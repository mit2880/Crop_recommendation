{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-20T12:43:00.580832500Z",
     "start_time": "2024-03-20T12:43:00.571772100Z"
    }
   },
   "outputs": [],
   "source": [
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\n",
    "    dbname=\"pgml_9mrdvtwlup0tw77\",\n",
    "    user=\"u_r4i5xrjkii5eqag\",\n",
    "    password=\"rinkeoaj2qaptx5\",\n",
    "    host=\"02f7e6f1-1adb-4347-835a-02c74fcccb0e.db.cloud.postgresml.org\",\n",
    "    port=\"6432\"\n",
    ")\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(\"SELECT n,p,k,Temperature,humidity,ph,Rainfall FROM Crop_recommendation\")\n",
    "model_names = cur.fetchall()\n",
    "\n",
    "cur.execute(\"SELECT label FROM Crop_recommendation\")\n",
    "target = cur.fetchall()\n",
    "# Close the cursor and connection\n",
    "cur.close()\n",
    "conn.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T09:49:33.028979Z",
     "start_time": "2024-03-20T09:49:26.773493100Z"
    }
   },
   "id": "68876d09ac362d5b",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[(2, 24, 38, 24.56, 91.64, 5.92, 111.97),\n (6, 18, 37, 19.66, 89.94, 5.94, 108.05),\n (8, 26, 36, 18.78, 87.4, 6.8, 102.52),\n (37, 18, 39, 24.15, 94.51, 6.42, 110.23),\n (0, 27, 38, 22.45, 89.9, 6.74, 109.39),\n (31, 25, 38, 24.96, 92.41, 6.5, 109.42),\n (31, 30, 29, 26.59, 90.99, 5.56, 104.9),\n (6, 30, 40, 22.77, 91.45, 6.36, 106.97),\n (22, 16, 27, 29.18, 90.27, 6.01, 188.93),\n (15, 11, 38, 23.13, 92.68, 6.63, 109.39),\n (14, 5, 36, 24.93, 85.19, 5.83, 104.77),\n (16, 10, 41, 24.77, 85.64, 6.74, 105.76),\n (36, 7, 37, 19.87, 86.36, 5.78, 108.32),\n (4, 20, 41, 24.27, 93.8, 6.54, 104.54),\n (29, 22, 40, 23.63, 89.73, 6.15, 107.68),\n (16, 15, 42, 19.68, 89.09, 6.89, 108.55),\n (18, 27, 41, 22.37, 92.31, 7.18, 104.82),\n (11, 18, 42, 21.58, 94.88, 5.94, 102.86),\n (5, 15, 38, 18.26, 88.17, 5.71, 108.08),\n (18, 23, 44, 23.71, 89.62, 6.18, 105.65),\n (9, 8, 40, 22.49, 89.92, 6.55, 111.66),\n (40, 27, 45, 21.66, 94.79, 5.89, 112.43),\n (22, 23, 44, 20.13, 89.32, 6.14, 107.34),\n (9, 16, 39, 18.41, 91.12, 6.1, 105.18),\n (12, 29, 40, 19.68, 89.75, 6.59, 111.28),\n (0, 17, 42, 23.2, 91.19, 6.86, 109.09),\n (2, 21, 44, 18.92, 87.31, 6.57, 102.8),\n (28, 6, 40, 22.11, 91.34, 6.77, 106.87),\n (8, 23, 44, 18.47, 89.69, 7.13, 108.48),\n (29, 16, 36, 19.81, 88.93, 5.74, 102.86),\n (17, 18, 43, 24.49, 90.84, 5.84, 103.2),\n (34, 21, 42, 18.76, 89.93, 6.65, 111.02),\n (21, 23, 42, 19.54, 90.3, 6.9, 104.37),\n (25, 17, 40, 18.91, 87.75, 6.61, 111.28),\n (8, 25, 36, 19.91, 94.95, 6.83, 104.03),\n (26, 18, 42, 19.73, 89.65, 6.91, 108.23),\n (4, 19, 42, 23.83, 87.84, 6.31, 111.22),\n (36, 24, 41, 24.94, 94.26, 7.01, 103.88),\n (5, 24, 40, 24.69, 93.87, 6.3, 104.67),\n (19, 17, 39, 24.72, 85.56, 6.73, 111.28),\n (39, 30, 38, 20.13, 87.6, 6.97, 108.07),\n (5, 29, 44, 21.02, 93.06, 5.58, 104.78),\n (4, 24, 43, 22.4, 88.15, 7.2, 109.87),\n (38, 21, 35, 20.34, 89.38, 5.84, 110.97),\n (37, 11, 36, 24.25, 85.56, 6.71, 106.92),\n (38, 51, 52, 32.66, 90.79, 6.93, 109.29),\n (29, 22, 43, 19.66, 87.95, 5.56, 106.04),\n (5, 21, 38, 22.43, 90.34, 6.11, 112.46),\n (22, 26, 38, 22.92, 85.13, 6.99, 110.24),\n (4, 18, 37, 22.92, 85.41, 7.13, 106.28),\n (21, 6, 41, 24.88, 89.4, 7.09, 107.2),\n (29, 21, 45, 23.41, 93.13, 6.75, 105.22),\n (23, 5, 44, 21.21, 94.26, 7.16, 107.57),\n (13, 7, 43, 18.2, 91.12, 7.01, 109.66),\n (5, 13, 37, 22.34, 89.79, 5.65, 103.32),\n (27, 24, 41, 24.33, 90.88, 6.61, 110.46),\n (7, 23, 35, 19.75, 88.72, 7.05, 102.55),\n (12, 20, 39, 19.86, 86.2, 6.03, 111.02),\n (4, 19, 43, 18.07, 93.15, 5.78, 106.36),\n (3, 9, 45, 23.89, 89.62, 6.54, 104.62),\n (1, 27, 36, 23.99, 93.34, 5.68, 104.99),\n (23, 30, 44, 20.94, 85.43, 6.12, 103.03),\n (24, 21, 42, 20.82, 87.23, 7.0, 109.44),\n (13, 30, 37, 20.86, 91.62, 6.28, 106.87),\n (40, 11, 44, 24.46, 86.11, 6.32, 111.38),\n (21, 9, 40, 24.51, 90.64, 5.96, 105.62),\n (3, 27, 44, 24.57, 92.03, 6.59, 110.96),\n (40, 29, 42, 24.63, 89.02, 7.1, 110.7),\n (14, 25, 40, 20.07, 90.98, 6.41, 103.71),\n (38, 14, 37, 21.81, 94.64, 6.66, 102.65),\n (34, 9, 36, 22.81, 86.34, 6.28, 110.44),\n (32, 14, 37, 22.73, 88.49, 6.83, 104.68),\n (18, 21, 35, 23.28, 94.94, 6.37, 111.14),\n (8, 23, 38, 19.3, 87.18, 7.01, 105.48),\n (15, 6, 41, 19.01, 88.84, 6.9, 108.68),\n (0, 5, 36, 24.35, 90.89, 6.15, 105.53),\n (22, 9, 44, 24.72, 88.88, 5.74, 112.19),\n (14, 8, 43, 21.93, 94.46, 7.05, 111.72),\n (31, 11, 45, 24.84, 86.89, 6.03, 107.64),\n (39, 17, 45, 18.1, 90.42, 6.92, 104.88),\n (10, 5, 42, 20.24, 91.09, 6.89, 109.25),\n (8, 28, 38, 23.23, 94.43, 6.84, 105.69),\n (32, 13, 42, 23.5, 92.98, 5.79, 106.62),\n (18, 9, 40, 19.45, 89.02, 5.63, 106.16),\n (20, 27, 41, 20.51, 92.52, 5.7, 110.58),\n (39, 25, 36, 18.9, 95.0, 5.57, 107.61),\n (20, 7, 45, 18.91, 89.24, 6.08, 112.48),\n (11, 10, 45, 22.63, 88.46, 6.4, 109.04),\n (40, 18, 43, 19.39, 86.79, 5.77, 109.91),\n (3, 26, 39, 24.38, 91.19, 7.08, 103.6),\n (9, 16, 36, 23.78, 92.93, 5.89, 106.98),\n (30, 20, 38, 22.6, 93.16, 7.06, 110.09),\n (40, 9, 41, 24.38, 85.4, 5.78, 106.13),\n (40, 30, 35, 20.89, 91.08, 6.27, 104.44),\n (32, 25, 35, 18.1, 85.71, 5.89, 107.01),\n (33, 23, 45, 20.0, 85.84, 7.12, 112.34),\n (4, 14, 41, 19.85, 89.81, 6.43, 102.82),\n (13, 17, 45, 21.25, 92.65, 7.16, 106.28),\n (39, 24, 39, 23.65, 93.33, 6.43, 109.81),\n (8, 28, 37, 23.88, 86.21, 6.08, 108.31),\n (91, 94, 46, 29.37, 76.25, 6.15, 92.83),\n (105, 95, 50, 27.33, 83.68, 5.85, 101.05),\n (108, 92, 53, 27.4, 82.96, 6.28, 104.94),\n (86, 76, 54, 29.32, 80.12, 5.93, 90.11),\n (80, 77, 49, 26.05, 79.4, 5.52, 113.23),\n (93, 94, 53, 25.87, 84.42, 6.08, 114.54),\n (90, 92, 55, 27.01, 80.19, 6.13, 97.33),\n (108, 89, 53, 29.55, 78.07, 5.81, 99.34),\n (108, 88, 55, 26.29, 83.39, 5.89, 113.87),\n (105, 77, 52, 29.16, 76.16, 5.82, 100.01),\n (118, 88, 52, 28.65, 82.69, 5.84, 98.75),\n (101, 87, 54, 29.07, 76.5, 6.38, 100.17),\n (95, 75, 50, 28.08, 75.26, 5.62, 118.28),\n (106, 85, 53, 27.2, 78.81, 5.92, 99.72),\n (86, 95, 49, 28.05, 78.05, 6.46, 108.4),\n (83, 79, 55, 25.15, 83.35, 5.57, 98.67),\n (85, 95, 47, 25.94, 78.34, 6.21, 119.85),\n (22, 16, 27, 29.18, 90.27, 6.01, 188.93),\n (100, 76, 45, 25.57, 75.94, 5.59, 102.79),\n (117, 86, 48, 28.7, 82.54, 6.23, 116.16),\n (114, 94, 53, 26.34, 76.85, 6.19, 118.69),\n (110, 78, 50, 25.94, 78.9, 5.92, 98.22),\n (94, 70, 48, 25.14, 84.88, 6.2, 91.46),\n (80, 71, 47, 27.51, 80.8, 6.16, 105.08),\n (114, 79, 51, 26.21, 82.34, 6.31, 112.07),\n (88, 78, 45, 29.1, 79.2, 6.32, 92.08),\n (112, 73, 48, 29.24, 77.32, 5.71, 90.67),\n (117, 76, 47, 25.56, 77.38, 6.12, 93.1),\n (111, 87, 48, 26.4, 81.36, 5.57, 98.17),\n (89, 83, 47, 28.1, 77.8, 5.63, 109.54),\n (93, 91, 47, 27.85, 83.31, 6.1, 117.29),\n (92, 81, 52, 27.39, 81.47, 6.44, 94.31),\n (105, 74, 45, 25.15, 81.38, 6.1, 119.22),\n (102, 71, 48, 28.65, 79.29, 5.7, 102.46),\n (94, 91, 51, 29.16, 76.67, 5.62, 109.58),\n (116, 71, 47, 27.57, 82.06, 6.44, 91.34),\n (117, 79, 49, 25.41, 82.36, 6.18, 112.98),\n (119, 72, 55, 25.99, 83.34, 6.22, 112.08),\n (99, 73, 53, 26.29, 81.06, 5.87, 118.67),\n (91, 84, 52, 29.15, 78.71, 6.39, 117.54),\n (80, 90, 47, 26.6, 79.36, 6.21, 107.39),\n (6, 30, 40, 22.77, 91.45, 6.36, 116.55),\n (25, 27, 41, 19.2, 94.28, 6.92, 112.4),\n (100, 80, 52, 27.54, 77.26, 6.05, 110.33),\n (109, 91, 53, 29.67, 83.51, 6.01, 110.25),\n (82, 78, 46, 25.06, 84.97, 5.74, 110.44),\n (106, 70, 55, 25.87, 78.52, 5.74, 116.3),\n (90, 86, 52, 25.85, 81.96, 5.79, 119.09),\n (83, 95, 50, 26.52, 77.8, 5.51, 108.85),\n (119, 90, 48, 28.67, 79.59, 5.99, 118.26),\n (107, 72, 45, 28.15, 81.54, 5.79, 91.41),\n (116, 81, 55, 26.42, 83.7, 5.92, 95.12),\n (101, 75, 50, 26.59, 81.41, 6.24, 109.98),\n (93, 81, 50, 27.72, 76.58, 6.04, 102.21),\n (95, 75, 45, 28.98, 82.96, 5.83, 109.02),\n (107, 71, 55, 29.42, 83.97, 6.09, 117.23),\n (83, 94, 47, 27.4, 81.11, 6.47, 112.14),\n (102, 73, 54, 26.4, 84.41, 5.72, 111.02),\n (86, 79, 45, 27.81, 82.69, 5.81, 99.21),\n (117, 86, 53, 25.2, 83.56, 5.7, 115.86),\n (111, 79, 53, 28.31, 75.77, 6.17, 119.7),\n (95, 74, 50, 25.9, 80.47, 6.0, 110.1),\n (91, 75, 55, 27.49, 76.11, 6.21, 109.28),\n (93, 83, 46, 29.38, 83.5, 5.77, 109.25),\n (92, 85, 51, 29.22, 81.08, 5.74, 108.86),\n (104, 80, 54, 27.09, 81.34, 5.88, 110.13),\n (103, 72, 51, 26.13, 81.81, 6.1, 104.48),\n (92, 75, 45, 29.01, 77.95, 5.67, 90.43),\n (93, 85, 49, 27.97, 79.29, 5.69, 119.48),\n (120, 87, 52, 28.08, 76.06, 5.91, 118.99),\n (108, 72, 46, 25.16, 84.98, 6.11, 90.95),\n (105, 88, 54, 25.79, 84.51, 6.02, 114.2),\n (98, 79, 50, 25.34, 84.47, 6.44, 91.06),\n (111, 88, 55, 29.45, 78.35, 5.51, 96.45),\n (97, 74, 45, 26.48, 78.52, 5.68, 113.12),\n (95, 82, 48, 27.39, 83.31, 5.72, 92.78),\n (89, 91, 55, 25.08, 80.26, 6.28, 94.33),\n (89, 85, 55, 26.67, 76.49, 6.28, 91.73),\n (118, 88, 51, 25.45, 79.49, 6.2, 100.66),\n (101, 92, 45, 28.23, 80.64, 5.76, 98.0),\n (99, 92, 47, 28.13, 77.48, 6.32, 103.5),\n (82, 77, 46, 28.95, 82.19, 5.9, 95.83),\n (90, 86, 55, 27.96, 84.15, 5.64, 97.56),\n (95, 88, 52, 28.0, 78.9, 6.24, 94.68),\n (104, 73, 46, 29.14, 80.12, 6.28, 90.45),\n (102, 73, 52, 27.91, 83.36, 6.36, 90.24),\n (100, 74, 52, 25.43, 81.54, 5.84, 96.48),\n (94, 89, 48, 28.56, 84.52, 5.65, 111.08),\n (99, 70, 46, 26.6, 83.0, 5.73, 100.51),\n (112, 87, 48, 27.2, 77.4, 6.2, 99.47),\n (117, 82, 45, 25.29, 79.29, 5.61, 105.42),\n (96, 86, 51, 29.91, 76.99, 6.26, 92.0),\n (113, 85, 45, 27.95, 76.64, 6.04, 109.09),\n (105, 93, 46, 25.01, 78.76, 5.76, 108.37),\n (85, 89, 51, 29.21, 84.7, 6.16, 108.55),\n (108, 94, 47, 27.36, 84.55, 6.39, 90.81),\n (92, 81, 52, 28.01, 76.53, 5.89, 103.7),\n (38, 51, 52, 32.66, 90.79, 6.93, 94.38),\n (82, 75, 55, 27.35, 78.49, 6.28, 92.16),\n (117, 81, 53, 29.51, 78.21, 5.51, 98.13),\n (2, 40, 27, 29.74, 47.55, 5.95, 90.1),\n (39, 24, 31, 33.56, 53.73, 4.76, 98.68),\n (21, 26, 27, 27.0, 47.68, 5.7, 95.85),\n (25, 22, 25, 33.56, 45.54, 5.98, 95.71),\n (0, 21, 32, 35.9, 54.26, 6.43, 92.2),\n (20, 19, 35, 34.18, 50.62, 6.11, 98.01),\n (19, 21, 34, 30.02, 53.19, 5.07, 97.73),\n (18, 17, 31, 31.75, 45.16, 5.67, 93.75),\n (11, 36, 33, 35.99, 52.23, 5.98, 95.37),\n (30, 28, 30, 31.87, 52.19, 5.06, 98.47),\n (18, 19, 27, 27.76, 52.35, 4.77, 94.11),\n (23, 23, 27, 34.72, 51.43, 5.16, 97.31),\n (37, 30, 34, 27.54, 53.64, 6.8, 99.35),\n (11, 27, 30, 27.7, 48.56, 6.39, 89.86),\n (12, 19, 31, 27.25, 52.66, 5.57, 91.87),\n (3, 28, 33, 30.34, 48.89, 5.76, 94.43),\n (37, 38, 32, 31.86, 45.53, 5.42, 91.56),\n (26, 37, 30, 35.4, 49.46, 6.17, 97.41),\n (14, 18, 30, 29.81, 52.14, 5.19, 95.75),\n (40, 16, 35, 34.16, 54.16, 4.95, 98.33),\n (4, 20, 25, 28.93, 47.94, 5.66, 99.98),\n (36, 25, 33, 27.98, 53.33, 5.55, 99.61),\n (30, 17, 31, 31.2, 54.5, 6.8, 94.63),\n (28, 37, 28, 32.13, 50.53, 6.1, 98.63),\n (38, 15, 30, 28.92, 48.14, 5.08, 97.01),\n (12, 37, 30, 31.1, 47.41, 4.55, 90.29),\n (38, 19, 31, 34.74, 49.09, 5.86, 90.65),\n (8, 33, 29, 29.98, 49.49, 6.44, 91.82),\n (15, 27, 28, 33.8, 46.13, 4.51, 90.83),\n (34, 16, 25, 30.07, 50.96, 6.11, 92.1),\n (11, 36, 31, 27.92, 51.78, 6.48, 100.26),\n (33, 29, 34, 31.41, 49.22, 6.83, 93.0),\n (12, 31, 26, 35.79, 51.94, 5.4, 100.22),\n (12, 34, 28, 33.36, 45.02, 6.14, 98.82),\n (5, 16, 31, 35.96, 48.7, 4.56, 98.01),\n (1, 30, 29, 28.33, 51.4, 6.43, 91.67),\n (16, 35, 31, 32.28, 50.19, 5.32, 95.99),\n (35, 18, 26, 31.99, 50.85, 5.28, 97.39),\n (4, 40, 26, 27.58, 48.57, 6.72, 95.84),\n (9, 29, 34, 29.38, 45.89, 5.73, 100.81),\n (11, 18, 42, 21.58, 94.88, 5.94, 90.22),\n (26, 32, 32, 30.91, 49.93, 6.81, 90.14),\n (34, 38, 31, 35.38, 45.58, 6.45, 97.42),\n (5, 32, 33, 32.32, 52.59, 5.84, 93.37),\n (31, 29, 26, 28.22, 47.41, 5.02, 97.77),\n (34, 34, 35, 27.27, 47.17, 6.42, 95.26),\n (36, 19, 32, 27.11, 50.71, 4.94, 92.37),\n (7, 17, 26, 34.89, 48.76, 6.41, 91.63),\n (38, 15, 27, 33.75, 48.5, 6.78, 92.26),\n (5, 19, 25, 27.35, 54.44, 6.44, 96.28),\n (37, 36, 26, 32.89, 52.61, 4.65, 94.49),\n (21, 31, 32, 35.39, 51.43, 5.25, 90.3),\n (37, 36, 27, 27.55, 47.91, 5.91, 90.4),\n (23, 23, 30, 32.82, 47.46, 4.76, 90.89),\n (36, 26, 26, 30.17, 51.08, 6.81, 95.23),\n (24, 33, 35, 29.26, 54.82, 5.34, 100.76),\n (26, 18, 30, 32.06, 51.08, 6.34, 96.6),\n (22, 17, 26, 28.7, 47.72, 4.75, 99.64),\n (11, 34, 32, 29.14, 49.41, 6.83, 97.55),\n (29, 35, 28, 28.35, 53.54, 6.97, 90.4),\n (22, 28, 26, 27.67, 45.42, 4.95, 92.85),\n (95, 75, 50, 28.08, 75.26, 5.62, 93.3),\n (1, 35, 34, 30.79, 46.7, 6.27, 92.21),\n (2, 24, 34, 28.89, 54.81, 6.47, 94.76),\n (39, 37, 25, 33.33, 45.61, 6.95, 98.29),\n (15, 36, 27, 27.79, 53.97, 5.64, 91.01),\n (3, 18, 31, 31.65, 48.21, 6.39, 91.1),\n (8, 38, 32, 29.75, 46.74, 4.98, 91.41),\n (33, 31, 34, 31.33, 50.22, 5.42, 89.78),\n (14, 29, 32, 35.64, 48.97, 6.94, 97.52),\n (18, 20, 26, 31.67, 51.99, 5.44, 89.98),\n (9, 21, 32, 32.27, 53.56, 5.87, 95.94),\n (20, 30, 27, 27.81, 51.59, 4.75, 95.9),\n (9, 38, 25, 34.59, 50.34, 5.5, 100.31),\n (26, 24, 34, 31.27, 52.24, 6.81, 89.74),\n (31, 36, 29, 33.94, 52.72, 6.46, 97.46),\n (14, 18, 35, 31.09, 47.02, 4.79, 91.47),\n (40, 16, 35, 31.89, 49.02, 6.48, 89.59),\n (28, 27, 34, 32.45, 50.7, 6.53, 95.05),\n (0, 17, 30, 35.47, 47.97, 6.28, 97.79),\n (1, 29, 29, 27.33, 49.3, 6.05, 93.53),\n (2, 36, 31, 30.9, 49.96, 5.73, 91.78),\n (12, 27, 26, 29.09, 45.57, 5.32, 96.24),\n (7, 28, 35, 30.02, 46.78, 4.67, 96.64),\n (0, 36, 26, 34.13, 51.26, 5.1, 96.39),\n (22, 16, 27, 29.18, 90.27, 6.01, 188.93),\n (27, 21, 30, 35.39, 52.49, 5.06, 91.23),\n (22, 38, 31, 31.53, 53.06, 5.82, 98.57),\n (22, 18, 31, 30.76, 47.94, 5.96, 90.39),\n (28, 23, 28, 30.02, 50.1, 5.68, 96.09),\n (7, 31, 27, 31.33, 47.59, 6.52, 94.67),\n (29, 34, 26, 33.88, 54.39, 6.27, 89.29),\n (8, 37, 33, 28.08, 54.96, 6.13, 97.45),\n (39, 16, 27, 35.54, 52.95, 4.93, 91.55),\n (40, 24, 25, 28.71, 50.44, 5.45, 95.89),\n (19, 38, 26, 31.48, 48.78, 4.53, 93.17),\n (21, 21, 30, 27.7, 51.42, 5.4, 100.77),\n (22, 18, 33, 30.41, 52.48, 6.62, 93.92),\n (31, 20, 30, 32.18, 54.01, 6.21, 91.89),\n (18, 26, 31, 32.61, 47.75, 5.42, 91.1),\n (24, 130, 195, 30.0, 81.54, 6.11, 67.13),\n (13, 144, 204, 30.73, 82.43, 6.09, 68.38),\n (22, 123, 205, 32.45, 83.89, 5.9, 68.74),\n (36, 125, 196, 37.47, 80.66, 6.16, 66.84),\n (24, 131, 196, 22.03, 83.74, 5.73, 65.34),\n (2, 123, 198, 39.65, 82.21, 6.25, 70.4),\n (35, 140, 197, 16.78, 82.75, 6.11, 66.76),\n (11, 122, 195, 12.14, 83.57, 5.65, 69.63),\n (6, 123, 203, 12.76, 81.62, 6.13, 66.78),\n (17, 134, 204, 39.04, 80.18, 6.5, 73.88),\n (25, 130, 197, 39.71, 82.69, 5.55, 74.92),\n (27, 145, 205, 9.47, 82.29, 5.8, 66.03),\n (9, 122, 201, 29.59, 80.92, 5.57, 68.06),\n (16, 139, 203, 17.83, 80.96, 6.28, 65.85),\n (32, 141, 204, 8.83, 82.9, 5.54, 67.24),\n (22, 138, 195, 27.83, 83.51, 6.21, 73.03),\n (31, 144, 202, 11.02, 80.56, 5.87, 68.24),\n (3, 136, 205, 17.59, 80.85, 6.33, 71.41),\n (28, 122, 197, 19.89, 82.73, 5.86, 69.66),\n (4, 136, 204, 29.94, 81.78, 5.9, 65.52),\n (39, 145, 201, 36.73, 80.59, 5.78, 72.24),\n (38, 132, 197, 20.42, 81.54, 5.93, 66.93),\n (36, 133, 198, 25.52, 83.98, 6.23, 69.17),\n (25, 121, 201, 30.51, 82.72, 5.59, 70.08),\n (15, 125, 199, 18.43, 80.56, 5.57, 69.76),\n (24, 140, 205, 12.09, 83.59, 5.93, 68.67),\n (13, 132, 203, 23.6, 82.48, 6.42, 73.24),\n (5, 126, 197, 12.8, 81.21, 6.42, 67.1),\n (30, 120, 200, 38.06, 82.25, 6.23, 65.7),\n (23, 142, 197, 39.07, 82.04, 6.0, 69.31),\n (26, 135, 203, 33.78, 81.16, 5.69, 74.54),\n (7, 126, 203, 16.76, 82.0, 5.66, 73.29),\n (32, 139, 198, 35.89, 82.67, 6.36, 66.54),\n (9, 141, 202, 21.01, 81.18, 6.12, 66.38),\n (38, 51, 52, 32.66, 90.79, 6.93, 68.69),\n (32, 129, 201, 16.36, 83.0, 6.49, 71.56),\n (3, 134, 199, 20.28, 81.32, 5.82, 71.07),\n (36, 7, 37, 19.87, 86.36, 5.78, 73.01),\n (14, 131, 198, 33.46, 83.87, 5.56, 67.92),\n (20, 122, 204, 11.8, 80.86, 6.49, 65.07),\n (40, 126, 201, 11.36, 80.03, 6.12, 71.18),\n (36, 128, 204, 25.24, 80.69, 5.7, 67.04),\n (11, 132, 197, 15.99, 81.24, 5.73, 74.4),\n (0, 137, 195, 22.44, 80.19, 6.33, 65.4),\n (19, 123, 200, 34.76, 81.04, 6.17, 65.7),\n (31, 136, 197, 31.11, 83.34, 5.65, 71.43),\n (4, 134, 200, 28.58, 80.96, 5.84, 73.34),\n (39, 139, 201, 41.19, 81.02, 5.54, 68.69),\n (8, 127, 196, 27.03, 83.17, 5.83, 70.96),\n (39, 138, 203, 21.19, 82.33, 6.4, 74.63),\n (32, 120, 204, 10.38, 83.45, 6.14, 67.39),\n (12, 142, 203, 31.31, 82.56, 5.97, 65.01),\n (8, 133, 195, 20.47, 80.98, 6.46, 71.3),\n (8, 139, 199, 29.37, 81.54, 6.34, 66.13),\n (21, 134, 202, 10.72, 80.02, 6.43, 65.3),\n (40, 140, 195, 14.98, 80.5, 6.29, 71.63),\n (39, 127, 202, 15.32, 81.67, 6.48, 71.6),\n (19, 120, 195, 18.74, 81.12, 5.93, 73.56),\n (21, 139, 201, 19.36, 83.36, 5.98, 67.15),\n (17, 136, 195, 41.21, 81.61, 6.39, 65.9),\n (33, 139, 203, 33.34, 82.51, 5.69, 70.68),\n (22, 133, 201, 23.82, 80.12, 6.0, 67.27),\n (32, 130, 196, 40.66, 81.25, 6.37, 74.03),\n (37, 135, 205, 11.83, 80.28, 5.51, 74.1),\n (15, 140, 195, 13.29, 83.54, 5.7, 65.8),\n (39, 132, 196, 35.83, 83.33, 5.78, 73.68),\n (40, 121, 199, 26.18, 81.04, 6.32, 66.06),\n (40, 132, 202, 24.58, 80.71, 5.97, 69.71),\n (29, 142, 203, 29.67, 83.71, 5.89, 66.48),\n (32, 121, 199, 39.37, 81.25, 6.13, 74.08),\n (6, 140, 205, 17.67, 82.93, 6.31, 69.87),\n (8, 120, 196, 24.07, 82.66, 6.05, 69.82),\n (34, 133, 202, 15.31, 80.1, 5.8, 74.82),\n (35, 135, 199, 21.77, 80.55, 6.4, 69.4),\n (16, 145, 199, 26.92, 80.77, 5.95, 69.31),\n (8, 136, 201, 41.66, 82.22, 5.61, 74.2),\n (25, 129, 195, 17.99, 81.18, 5.78, 72.37),\n (16, 130, 201, 29.12, 82.79, 5.68, 68.85),\n (39, 129, 203, 34.39, 83.18, 5.86, 71.03),\n (38, 135, 203, 41.36, 82.8, 6.44, 69.92),\n (33, 120, 205, 35.12, 82.27, 5.55, 69.72),\n (95, 75, 50, 28.08, 75.26, 5.62, 73.7),\n (1, 132, 200, 16.28, 82.94, 5.62, 66.57),\n (39, 140, 203, 21.12, 80.63, 6.35, 69.28),\n (28, 145, 202, 19.21, 82.9, 6.48, 66.83),\n (6, 128, 200, 25.96, 82.58, 5.84, 70.32),\n (6, 139, 199, 25.67, 81.62, 6.29, 74.11),\n (29, 122, 196, 41.95, 81.16, 5.64, 73.07),\n (37, 144, 197, 11.19, 80.81, 6.42, 66.34),\n (38, 120, 197, 17.54, 82.95, 6.32, 73.77),\n (38, 141, 198, 13.06, 80.28, 5.76, 70.76),\n (14, 121, 203, 9.72, 83.75, 6.16, 74.46),\n (6, 125, 204, 27.92, 82.93, 5.73, 69.92),\n (32, 138, 197, 9.54, 80.73, 5.91, 69.44),\n (11, 124, 204, 13.43, 80.07, 6.36, 71.4),\n (23, 138, 200, 9.85, 80.23, 5.97, 68.43),\n (40, 143, 201, 24.97, 82.73, 6.48, 66.7),\n (6, 142, 202, 27.24, 82.95, 6.22, 70.43),\n (37, 124, 195, 18.71, 83.48, 6.21, 66.6),\n (35, 134, 204, 9.95, 82.55, 5.84, 66.01),\n (119, 25, 51, 26.47, 80.92, 6.28, 53.66),\n (119, 19, 55, 25.19, 83.45, 6.82, 46.87),\n (105, 30, 50, 25.3, 81.78, 6.38, 57.04),\n (114, 8, 50, 24.75, 88.31, 6.58, 57.96),\n (93, 22, 52, 26.59, 81.33, 6.93, 41.88),\n (80, 26, 55, 24.53, 88.99, 6.14, 49.12),\n (85, 27, 45, 26.07, 88.73, 6.47, 57.8),\n (85, 22, 53, 25.97, 89.77, 6.85, 59.46),\n (82, 22, 45, 26.22, 85.35, 6.51, 54.6),\n (118, 13, 54, 24.41, 89.82, 6.04, 44.08),\n (83, 25, 53, 26.49, 80.05, 6.06, 57.73),\n (86, 15, 47, 24.04, 84.18, 6.42, 53.79),\n (101, 10, 47, 25.54, 83.32, 6.94, 57.57),\n (119, 9, 50, 26.75, 83.92, 6.25, 40.79),\n (104, 17, 46, 25.71, 80.23, 6.19, 43.09),\n (95, 12, 51, 25.76, 84.17, 6.68, 44.22),\n (102, 14, 52, 26.79, 89.65, 6.51, 57.74),\n (1, 135, 203, 22.78, 92.7, 5.62, 57.45),\n (81, 18, 50, 26.81, 88.23, 6.43, 58.8),\n (103, 17, 51, 25.11, 80.03, 6.21, 44.21),\n (105, 14, 50, 26.21, 87.69, 6.42, 59.66),\n (97, 8, 52, 24.91, 86.97, 6.24, 49.49),\n (120, 19, 49, 25.79, 84.27, 6.76, 56.45),\n (95, 16, 55, 25.27, 87.55, 6.61, 40.13),\n (83, 29, 52, 25.76, 87.59, 6.7, 46.05),\n (83, 9, 45, 25.85, 89.13, 6.05, 46.85),\n (91, 21, 50, 24.34, 81.44, 6.76, 48.32),\n (116, 5, 54, 25.38, 80.99, 6.65, 57.23),\n (112, 28, 54, 24.86, 85.05, 6.74, 55.3),\n (88, 29, 51, 24.72, 88.95, 6.1, 48.46),\n (118, 15, 45, 24.21, 84.21, 6.54, 48.01),\n (92, 21, 48, 25.82, 82.04, 6.38, 54.83),\n (106, 14, 45, 24.47, 84.16, 6.42, 57.27),\n (99, 5, 47, 24.13, 84.84, 6.65, 51.19),\n (98, 8, 51, 26.18, 86.52, 6.26, 49.43),\n (108, 22, 46, 26.18, 86.73, 6.12, 53.33),\n (119, 7, 55, 26.04, 84.64, 6.03, 44.4),\n (117, 27, 48, 26.53, 82.39, 6.84, 54.31),\n (109, 10, 53, 26.82, 87.83, 6.55, 46.06),\n (80, 16, 46, 25.5, 81.4, 6.94, 48.48),\n (100, 18, 52, 26.2, 80.38, 6.88, 56.48),\n (91, 7, 53, 25.14, 89.28, 6.46, 43.53),\n (86, 6, 53, 25.92, 83.47, 6.92, 42.11),\n (107, 5, 52, 26.66, 89.98, 6.88, 57.41),\n (103, 16, 49, 24.07, 81.64, 6.92, 51.75),\n (101, 20, 48, 24.68, 82.75, 6.21, 57.06),\n (85, 25, 47, 26.11, 87.64, 6.3, 58.48),\n (84, 7, 51, 26.82, 87.66, 6.4, 55.74),\n (102, 28, 54, 25.16, 80.28, 6.86, 55.5),\n (98, 25, 52, 25.28, 83.15, 6.22, 49.29),\n (97, 25, 50, 26.22, 80.9, 6.09, 49.09),\n (90, 16, 45, 24.92, 80.62, 6.29, 50.56),\n (95, 12, 46, 26.22, 81.01, 6.32, 54.65),\n (82, 23, 49, 26.81, 87.22, 6.87, 51.7),\n (82, 25, 51, 24.31, 87.47, 6.07, 48.11),\n (110, 28, 46, 24.29, 88.05, 6.5, 51.26),\n (118, 21, 51, 24.43, 86.34, 6.68, 48.58),\n (120, 20, 45, 25.67, 88.7, 6.11, 54.23),\n (91, 7, 52, 25.08, 83.46, 6.41, 56.4),\n (81, 6, 55, 24.89, 85.87, 6.11, 51.71),\n (101, 13, 54, 25.43, 82.91, 6.83, 56.34),\n (101, 17, 55, 24.37, 87.13, 6.45, 44.64),\n (111, 6, 53, 26.49, 88.59, 6.31, 46.06),\n (107, 10, 49, 25.83, 89.0, 6.76, 45.25),\n (115, 11, 46, 24.42, 89.4, 6.62, 40.32),\n (84, 25, 52, 24.37, 81.25, 6.13, 44.21),\n (120, 7, 47, 24.25, 83.04, 6.65, 54.77),\n (91, 12, 46, 24.64, 85.5, 6.34, 48.31),\n (89, 22, 52, 24.9, 86.11, 6.22, 53.15),\n (113, 19, 46, 25.42, 81.12, 6.29, 49.52),\n (97, 22, 50, 26.26, 86.15, 6.77, 58.98),\n (117, 30, 50, 24.9, 87.21, 6.74, 46.59),\n (90, 14, 52, 24.85, 89.2, 6.39, 59.68),\n (104, 23, 47, 26.98, 86.7, 6.77, 42.91),\n (81, 16, 45, 26.9, 86.25, 6.73, 59.76),\n (88, 5, 47, 25.86, 86.67, 6.66, 41.17),\n (22, 16, 27, 29.18, 90.27, 6.01, 188.93),\n (81, 18, 50, 26.44, 80.92, 6.51, 47.82),\n (95, 75, 50, 28.08, 75.26, 5.62, 50.79),\n (108, 23, 51, 26.84, 83.85, 6.11, 40.23),\n (113, 30, 50, 26.04, 83.99, 6.28, 43.88),\n (83, 10, 53, 24.93, 85.01, 6.2, 48.76),\n (101, 11, 51, 25.51, 84.24, 6.79, 44.21),\n (114, 21, 55, 25.44, 87.94, 6.47, 57.52),\n (99, 6, 45, 26.13, 86.55, 6.0, 40.71),\n (92, 20, 55, 25.1, 87.53, 6.59, 59.27),\n (92, 7, 48, 26.28, 86.63, 6.96, 54.39),\n (91, 24, 55, 26.27, 83.09, 6.26, 46.77),\n (110, 21, 54, 26.74, 87.82, 6.75, 47.46),\n (112, 25, 51, 25.05, 85.57, 6.93, 56.72),\n (89, 25, 54, 24.69, 85.57, 6.35, 48.99),\n (100, 10, 53, 24.54, 84.61, 6.21, 42.01),\n (83, 22, 54, 25.9, 81.97, 6.28, 54.5),\n (95, 14, 50, 26.63, 84.32, 6.56, 56.32),\n (119, 30, 49, 25.36, 80.46, 6.9, 47.72),\n (97, 12, 47, 25.29, 89.64, 6.77, 58.29),\n (110, 7, 45, 26.64, 84.7, 6.19, 48.32),\n (96, 18, 50, 25.33, 84.31, 6.9, 41.53),\n (83, 23, 55, 26.9, 83.89, 6.46, 43.97),\n (120, 24, 47, 26.99, 89.41, 6.26, 58.55),\n (115, 17, 55, 27.58, 94.12, 6.78, 28.08),\n (114, 27, 48, 27.82, 93.04, 6.53, 26.32),\n (101, 25, 52, 29.1, 94.22, 6.75, 22.52),\n (118, 18, 52, 28.05, 90.83, 6.56, 20.76),\n (95, 26, 45, 29.92, 94.56, 6.12, 28.16),\n (81, 25, 49, 29.87, 93.25, 6.08, 26.26),\n (117, 24, 53, 29.17, 92.21, 6.29, 21.3),\n (114, 30, 51, 29.25, 90.07, 6.07, 25.93),\n (113, 6, 52, 27.76, 90.36, 6.74, 25.22),\n (108, 26, 52, 28.83, 94.27, 6.2, 26.24),\n (81, 30, 48, 28.52, 92.1, 6.04, 29.87),\n (115, 9, 52, 29.07, 90.98, 6.02, 29.12),\n (83, 7, 45, 29.08, 90.74, 6.7, 25.33),\n (84, 21, 55, 28.47, 94.79, 6.49, 21.08),\n (109, 26, 45, 28.28, 90.39, 6.22, 21.59),\n (95, 27, 55, 28.47, 91.21, 6.16, 20.89),\n (119, 5, 55, 29.69, 94.3, 6.17, 26.84),\n (110, 14, 51, 27.02, 91.67, 6.09, 21.26),\n (82, 18, 48, 29.1, 94.17, 6.16, 26.71),\n (87, 14, 48, 29.69, 92.59, 6.61, 29.11),\n (85, 9, 53, 28.21, 92.87, 6.45, 28.79),\n (100, 6, 53, 29.05, 93.92, 6.11, 23.67),\n (107, 12, 46, 29.57, 93.62, 6.56, 27.57),\n (91, 13, 47, 29.11, 92.44, 6.14, 27.96),\n (102, 25, 50, 28.2, 92.91, 6.1, 20.36),\n (117, 25, 53, 29.12, 92.13, 6.41, 24.52),\n (85, 21, 52, 29.63, 90.1, 6.08, 23.7),\n (104, 25, 55, 29.81, 90.37, 6.12, 22.69),\n (102, 24, 54, 27.72, 90.94, 6.7, 22.82),\n (116, 25, 50, 29.26, 92.92, 6.09, 28.71),\n (100, 17, 48, 29.73, 94.3, 6.37, 26.52),\n (110, 25, 54, 28.91, 90.78, 6.43, 23.44),\n (104, 25, 51, 28.96, 93.88, 6.47, 23.56),\n (107, 11, 54, 28.59, 91.34, 6.09, 29.44),\n (98, 26, 52, 27.34, 90.7, 6.15, 28.69),\n (88, 17, 52, 29.9, 90.75, 6.65, 25.38),\n (87, 25, 46, 27.43, 90.03, 6.38, 21.75),\n (120, 8, 46, 29.56, 90.71, 6.73, 28.37),\n (95, 13, 46, 29.84, 93.76, 6.13, 23.28),\n (108, 22, 47, 28.54, 91.73, 6.16, 25.13),\n (82, 13, 52, 27.12, 94.87, 6.44, 26.52),\n (120, 23, 55, 27.84, 91.61, 6.73, 26.48),\n (110, 22, 47, 29.03, 91.82, 6.24, 24.94),\n (95, 23, 45, 27.82, 90.57, 6.27, 21.19),\n (106, 10, 49, 27.73, 92.01, 6.35, 20.21),\n (99, 12, 52, 28.7, 94.31, 6.0, 22.22),\n (106, 20, 51, 29.73, 90.97, 6.34, 20.49),\n (83, 11, 53, 29.54, 92.92, 6.16, 21.97),\n (117, 19, 55, 28.8, 91.78, 6.12, 25.16),\n (98, 26, 49, 27.29, 90.53, 6.13, 23.5),\n (113, 20, 48, 27.47, 94.88, 6.44, 27.28),\n (101, 17, 47, 29.49, 94.73, 6.19, 26.31),\n (98, 7, 45, 27.79, 92.51, 6.16, 26.85),\n (93, 22, 48, 29.13, 91.52, 6.78, 21.9),\n (95, 21, 47, 27.93, 93.56, 6.43, 20.66),\n (109, 12, 48, 29.46, 92.13, 6.71, 20.76),\n (118, 12, 47, 27.97, 92.17, 6.01, 28.95),\n (100, 14, 49, 29.49, 91.08, 6.37, 26.02),\n (89, 9, 47, 29.47, 90.77, 6.67, 28.75),\n (95, 16, 46, 27.08, 90.14, 6.75, 24.45),\n (95, 7, 45, 27.3, 90.8, 6.03, 25.09),\n (87, 6, 45, 29.83, 90.79, 6.4, 22.84),\n (93, 20, 50, 29.93, 93.23, 6.45, 24.35),\n (84, 29, 49, 29.94, 93.91, 6.25, 20.39),\n (111, 5, 47, 28.03, 91.47, 6.27, 21.18),\n (111, 5, 52, 29.88, 94.04, 6.14, 21.0),\n (111, 15, 54, 27.71, 92.91, 6.19, 22.06),\n (89, 11, 47, 29.79, 94.65, 6.33, 27.87),\n (110, 15, 48, 28.58, 92.87, 6.21, 27.6),\n (95, 30, 52, 29.48, 90.34, 6.64, 26.04),\n (115, 12, 52, 27.51, 94.96, 6.69, 21.02),\n (120, 25, 50, 28.05, 94.82, 6.33, 21.85),\n (102, 11, 45, 29.03, 93.13, 6.36, 24.16),\n (94, 5, 55, 28.59, 91.89, 6.09, 26.88),\n (84, 18, 46, 27.09, 93.42, 6.78, 25.32),\n (107, 22, 54, 28.0, 90.85, 6.63, 21.62),\n (80, 18, 52, 27.87, 91.15, 6.48, 24.05),\n (86, 18, 45, 28.97, 90.72, 6.57, 22.26),\n (113, 28, 48, 28.88, 92.49, 6.17, 24.44),\n (115, 18, 53, 29.17, 94.2, 6.01, 22.07),\n (82, 20, 54, 29.34, 90.02, 6.54, 21.45),\n (98, 22, 47, 29.07, 91.92, 6.34, 28.84),\n (117, 25, 54, 28.68, 92.51, 6.15, 29.11),\n (83, 15, 49, 28.93, 91.39, 6.44, 23.2),\n (120, 16, 51, 28.0, 91.64, 6.55, 23.29),\n (111, 5, 50, 27.59, 91.8, 6.4, 24.84),\n (85, 21, 47, 29.87, 90.61, 6.19, 24.7),\n (90, 23, 54, 28.56, 90.46, 6.16, 27.27),\n (99, 29, 55, 29.19, 91.46, 6.66, 26.48),\n (102, 11, 47, 27.99, 92.78, 6.5, 27.15),\n (80, 18, 51, 28.05, 91.82, 6.71, 20.77),\n (87, 21, 52, 27.35, 94.29, 6.07, 27.21),\n (114, 8, 52, 29.34, 94.55, 6.42, 28.23),\n (99, 6, 46, 28.61, 94.22, 6.4, 28.99),\n (89, 25, 50, 27.05, 91.35, 6.38, 25.08),\n (96, 13, 55, 29.53, 94.57, 6.7, 21.14),\n (82, 26, 47, 28.5, 93.47, 6.57, 24.2),\n (106, 21, 52, 28.9, 94.79, 6.29, 23.04),\n (90, 15, 52, 27.05, 91.38, 6.45, 23.66),\n (106, 16, 54, 28.96, 91.7, 6.59, 24.75),\n (24, 128, 196, 22.75, 90.69, 5.52, 110.43),\n (7, 144, 197, 23.85, 94.35, 6.13, 114.05),\n (14, 128, 205, 22.61, 94.59, 6.23, 116.04),\n (8, 120, 201, 21.19, 91.13, 6.32, 122.23),\n (12, 20, 39, 19.86, 86.2, 6.03, 116.08),\n (32, 137, 204, 22.86, 93.13, 5.82, 117.73),\n (27, 139, 205, 22.48, 93.41, 5.77, 105.55),\n (0, 123, 205, 22.03, 92.96, 5.79, 121.13),\n (22, 144, 196, 21.91, 91.69, 6.5, 117.08),\n (1, 124, 199, 23.71, 93.27, 5.66, 112.67),\n (30, 122, 197, 21.38, 92.72, 5.57, 106.14),\n (29, 121, 196, 22.85, 94.32, 6.08, 123.6),\n (13, 126, 204, 23.11, 92.8, 6.38, 108.18),\n (9, 139, 199, 23.25, 94.54, 5.87, 105.36),\n (0, 133, 200, 23.67, 90.49, 5.71, 104.23),\n (30, 143, 199, 23.77, 90.6, 5.8, 102.26),\n (36, 140, 198, 23.34, 91.48, 6.28, 104.43),\n (37, 137, 199, 22.64, 90.18, 5.7, 108.34),\n (33, 121, 203, 22.46, 94.76, 5.61, 114.84),\n (7, 144, 195, 22.96, 93.58, 5.86, 104.65),\n (35, 128, 205, 21.07, 93.57, 6.04, 107.87),\n (29, 128, 198, 22.44, 92.71, 5.69, 121.5),\n (2, 143, 196, 22.71, 90.45, 5.67, 109.89),\n (34, 140, 198, 21.7, 93.44, 5.75, 115.18),\n (29, 144, 204, 22.43, 92.49, 5.8, 119.1),\n (32, 141, 203, 21.26, 92.84, 5.82, 109.07),\n (13, 144, 197, 22.92, 94.9, 6.28, 105.69),\n (25, 143, 198, 22.81, 91.52, 6.03, 107.86),\n (9, 137, 200, 21.12, 90.69, 5.64, 102.8),\n (6, 144, 198, 21.11, 90.32, 5.56, 104.51),\n (37, 126, 196, 23.6, 90.98, 5.6, 107.17),\n (2, 120, 203, 23.13, 94.71, 5.89, 108.62),\n (11, 143, 197, 22.98, 93.32, 5.88, 122.2),\n (10, 141, 201, 22.13, 90.98, 6.39, 104.54),\n (24, 142, 202, 22.54, 91.48, 5.71, 101.85),\n (23, 138, 195, 22.49, 91.7, 5.8, 124.39),\n (18, 125, 204, 22.36, 94.48, 6.05, 116.74),\n (13, 121, 196, 22.21, 93.51, 6.44, 120.16),\n (26, 122, 202, 22.45, 94.74, 5.62, 107.18),\n (28, 123, 202, 22.77, 92.12, 6.44, 120.44),\n (26, 121, 201, 22.19, 90.03, 6.16, 112.31),\n (21, 137, 196, 23.61, 91.7, 5.81, 123.59),\n (21, 135, 198, 23.86, 94.92, 5.77, 105.02),\n (5, 144, 205, 21.42, 92.63, 6.18, 102.8),\n (2, 123, 205, 22.37, 90.79, 5.74, 124.98),\n (15, 133, 199, 24.0, 91.61, 5.82, 117.61),\n (31, 130, 198, 21.8, 92.73, 5.55, 120.06),\n (25, 143, 200, 23.8, 92.8, 6.02, 100.62),\n (16, 143, 204, 23.71, 91.53, 5.63, 121.9),\n (19, 122, 202, 23.34, 90.38, 5.81, 112.9),\n (10, 125, 196, 22.31, 90.04, 5.73, 113.07),\n (20, 139, 202, 23.5, 92.21, 5.67, 107.99),\n (28, 123, 198, 23.46, 91.46, 5.68, 111.78),\n (28, 136, 200, 23.06, 92.4, 6.25, 114.74),\n (2, 131, 199, 22.47, 91.23, 6.02, 124.22),\n (2, 140, 197, 22.7, 92.82, 5.53, 105.05),\n (27, 138, 201, 23.67, 93.9, 5.95, 105.4),\n (30, 127, 204, 22.5, 92.46, 6.13, 100.93),\n (32, 145, 203, 23.83, 90.84, 6.41, 109.6),\n (29, 139, 205, 23.64, 93.74, 6.16, 116.69),\n (26, 126, 195, 21.41, 92.99, 5.88, 118.4),\n (22, 16, 27, 29.18, 90.27, 6.01, 188.93),\n (6, 124, 200, 22.98, 93.85, 5.97, 109.59),\n (35, 138, 200, 21.2, 90.81, 5.67, 103.68),\n (17, 136, 196, 23.87, 90.5, 5.88, 103.05),\n (33, 134, 205, 21.04, 94.34, 6.09, 114.74),\n (16, 143, 197, 22.62, 93.52, 5.9, 116.93),\n (27, 120, 200, 21.45, 90.75, 6.11, 116.7),\n (29, 145, 205, 22.81, 92.13, 6.21, 109.34),\n (3, 141, 197, 21.98, 91.13, 6.14, 115.48),\n (15, 123, 204, 22.53, 92.55, 6.37, 115.38),\n (5, 136, 195, 22.36, 91.92, 6.26, 107.77),\n (10, 136, 204, 21.2, 92.16, 6.28, 105.86),\n (7, 141, 195, 23.88, 93.45, 5.51, 104.91),\n (2, 129, 201, 22.78, 94.37, 5.68, 122.14),\n (29, 138, 197, 22.19, 92.44, 5.83, 121.66),\n (30, 137, 200, 22.91, 90.7, 5.6, 118.6),\n (29, 132, 204, 23.09, 90.23, 6.1, 108.22),\n (14, 139, 197, 21.72, 92.84, 6.06, 121.7),\n (18, 125, 203, 22.44, 91.59, 6.16, 102.56),\n (33, 143, 204, 21.13, 91.96, 5.81, 122.54),\n (40, 144, 196, 22.72, 92.25, 5.99, 107.03),\n (116, 71, 47, 27.57, 82.06, 6.44, 117.66),\n (38, 135, 203, 23.76, 93.66, 5.97, 100.83),\n (28, 130, 196, 22.13, 94.68, 6.06, 112.92),\n (35, 142, 203, 21.17, 90.24, 5.9, 123.65),\n (12, 129, 205, 22.36, 91.16, 6.12, 118.68),\n (1, 135, 203, 22.78, 92.7, 5.62, 113.78),\n (0, 145, 205, 21.23, 90.1, 5.52, 113.98),\n (95, 75, 50, 28.08, 75.26, 5.62, 110.71),\n (35, 131, 203, 22.43, 93.92, 5.89, 102.72),\n (29, 140, 195, 23.64, 90.95, 5.56, 116.74),\n (33, 138, 198, 22.29, 90.69, 6.22, 122.74),\n (14, 140, 197, 23.35, 90.9, 6.07, 113.04),\n (35, 145, 195, 22.04, 94.58, 6.23, 110.98),\n (40, 120, 197, 23.81, 92.49, 5.89, 119.63),\n (25, 132, 198, 22.32, 90.85, 5.73, 100.12),\n (31, 137, 196, 22.14, 93.83, 6.4, 120.63),\n (36, 144, 196, 23.65, 94.51, 6.5, 115.36),\n (10, 140, 197, 22.17, 90.27, 6.23, 124.47),\n (22, 30, 12, 15.78, 92.51, 6.35, 119.04),\n (37, 6, 13, 26.03, 91.51, 7.51, 101.28),\n (27, 13, 6, 13.36, 91.36, 7.34, 111.23),\n (7, 16, 9, 18.88, 92.04, 7.81, 114.67),\n (20, 7, 9, 29.48, 91.58, 7.13, 111.17),\n (26, 27, 10, 28.07, 92.91, 6.08, 114.13),\n (40, 120, 197, 23.81, 92.49, 5.89, 112.54),\n (0, 18, 14, 29.77, 92.01, 7.21, 114.42),\n (39, 24, 14, 30.55, 90.9, 7.19, 106.07),\n (13, 23, 6, 23.96, 90.26, 7.37, 102.7),\n (21, 17, 15, 23.98, 91.55, 7.46, 118.49),\n (33, 12, 8, 25.26, 90.31, 6.82, 117.37),\n (6, 9, 12, 31.08, 90.14, 7.03, 109.69),\n (19, 7, 10, 14.78, 91.22, 6.12, 100.2),\n (24, 18, 6, 26.57, 94.45, 6.29, 116.38),\n (9, 11, 8, 24.86, 94.39, 6.56, 111.78),\n (31, 8, 7, 34.51, 93.64, 7.16, 103.57),\n (22, 17, 5, 24.12, 90.72, 6.95, 102.84),\n (13, 5, 8, 23.85, 90.11, 7.47, 103.92),\n (16, 8, 9, 24.6, 91.28, 7.6, 111.29),\n (4, 13, 6, 15.63, 94.26, 7.56, 101.47),\n (0, 25, 14, 19.34, 91.98, 6.36, 116.45),\n (8, 7, 10, 28.26, 91.98, 6.93, 105.21),\n (4, 23, 5, 22.68, 93.36, 7.48, 110.33),\n (33, 14, 8, 21.03, 92.96, 7.68, 110.68),\n (30, 7, 15, 33.23, 91.06, 7.83, 115.77),\n (21, 29, 12, 22.3, 92.16, 6.44, 117.37),\n (11, 14, 5, 11.5, 94.89, 6.95, 115.57),\n (9, 8, 15, 14.34, 94.36, 7.99, 110.22),\n (5, 18, 14, 33.11, 93.48, 7.43, 119.17),\n (29, 25, 14, 30.49, 90.46, 7.78, 113.33),\n (33, 12, 15, 30.26, 92.03, 6.05, 116.72),\n (8, 16, 6, 12.23, 90.26, 7.11, 108.42),\n (15, 14, 8, 10.01, 90.22, 6.22, 119.39),\n (16, 7, 8, 22.79, 90.61, 6.42, 116.51),\n (0, 12, 7, 20.18, 90.65, 6.97, 116.81),\n (5, 25, 6, 30.72, 94.01, 6.01, 106.81),\n (6, 8, 11, 24.36, 92.4, 6.6, 119.69),\n (10, 5, 5, 21.21, 91.35, 7.82, 112.98),\n (1, 17, 6, 10.79, 91.38, 6.82, 117.53),\n (1, 30, 10, 11.9, 91.35, 7.29, 103.58),\n (0, 23, 15, 22.57, 93.37, 7.6, 109.86),\n (24, 27, 9, 18.87, 93.25, 6.16, 119.39),\n (36, 11, 13, 17.34, 93.05, 7.19, 112.72),\n (40, 21, 8, 34.91, 92.88, 7.42, 102.19),\n (40, 22, 6, 24.54, 91.91, 6.49, 115.98),\n (32, 18, 13, 13.84, 91.75, 6.04, 107.99),\n (9, 10, 10, 22.36, 93.52, 6.01, 101.52),\n (13, 16, 8, 34.74, 93.12, 6.95, 100.2),\n (15, 9, 11, 11.55, 94.15, 7.91, 108.83),\n (29, 11, 5, 23.13, 91.95, 7.64, 104.42),\n (1, 15, 9, 29.98, 94.55, 7.53, 115.36),\n (18, 5, 11, 20.88, 90.94, 6.25, 102.46),\n (14, 22, 9, 17.25, 91.14, 6.54, 112.51),\n (33, 15, 7, 15.83, 91.68, 7.65, 109.76),\n (4, 6, 7, 23.01, 91.12, 6.71, 112.67),\n (17, 16, 14, 16.4, 92.18, 6.63, 102.94),\n (12, 20, 10, 24.45, 93.11, 6.53, 109.47),\n (34, 29, 8, 31.88, 91.15, 6.45, 105.34),\n (39, 28, 10, 31.35, 91.48, 7.18, 109.15),\n (31, 25, 12, 18.05, 90.04, 7.02, 111.78),\n (12, 6, 8, 30.85, 92.87, 6.39, 107.41),\n (12, 29, 13, 22.46, 91.53, 7.57, 118.01),\n (26, 11, 11, 13.7, 90.96, 7.61, 106.29),\n (19, 24, 15, 20.49, 93.72, 7.14, 111.84),\n (39, 21, 9, 13.21, 94.03, 6.35, 106.27),\n (16, 29, 13, 32.32, 93.68, 6.2, 117.62),\n (36, 29, 13, 20.68, 90.92, 7.83, 109.75),\n (37, 23, 12, 31.53, 90.51, 6.4, 113.12),\n (39, 9, 15, 25.35, 91.81, 7.99, 116.76),\n (31, 5, 14, 17.67, 91.7, 6.58, 110.69),\n (18, 12, 8, 12.59, 91.82, 6.21, 119.39),\n (20, 20, 10, 11.87, 93.68, 6.98, 106.06),\n (5, 8, 5, 11.03, 92.23, 6.56, 112.77),\n (20, 8, 12, 25.3, 94.96, 7.26, 117.97),\n (25, 21, 11, 32.24, 90.15, 6.46, 104.71),\n (14, 19, 14, 17.68, 94.36, 6.7, 108.06),\n (37, 18, 12, 10.27, 90.19, 7.4, 106.7),\n (26, 15, 6, 17.22, 94.79, 6.91, 108.01),\n (13, 22, 5, 19.67, 90.5, 7.76, 100.17),\n (32, 25, 9, 10.36, 93.76, 7.8, 101.15),\n (19, 7, 9, 27.26, 91.71, 6.97, 101.14),\n (1, 124, 199, 23.71, 93.27, 5.66, 115.57),\n (30, 122, 197, 21.38, 92.72, 5.57, 113.25),\n (7, 17, 10, 10.16, 91.22, 6.47, 106.36),\n (18, 23, 8, 21.49, 93.44, 6.41, 101.48),\n (7, 20, 12, 16.53, 94.77, 6.48, 110.04),\n (20, 23, 11, 31.85, 90.12, 6.41, 109.95),\n (18, 14, 11, 28.05, 90.01, 6.55, 117.13),\n (34, 11, 10, 31.75, 94.6, 7.36, 115.2),\n (20, 29, 10, 29.07, 93.27, 7.37, 100.79),\n (37, 24, 13, 19.14, 90.71, 7.85, 108.02),\n (12, 8, 10, 16.15, 91.44, 8.0, 107.43),\n (34, 10, 14, 34.05, 92.06, 6.73, 116.8),\n (6, 13, 9, 34.51, 90.56, 7.79, 118.33),\n (27, 30, 5, 32.72, 90.55, 7.66, 113.33),\n (13, 8, 12, 25.16, 92.55, 7.11, 114.31),\n (6, 7, 7, 27.68, 94.47, 7.2, 114.0),\n (40, 17, 15, 21.35, 90.95, 7.87, 107.09),\n (31, 26, 9, 11.7, 93.26, 7.57, 103.2),\n (61, 68, 50, 35.21, 91.5, 6.79, 243.07),\n (58, 46, 45, 42.39, 90.79, 6.58, 88.47),\n (45, 47, 55, 38.42, 91.14, 6.75, 119.27),\n (39, 65, 53, 35.33, 92.12, 6.56, 235.61),\n (31, 68, 45, 42.92, 90.08, 6.94, 196.24),\n (70, 68, 45, 33.84, 92.85, 6.99, 203.4),\n (68, 62, 50, 33.2, 92.76, 6.98, 197.53),\n (34, 65, 47, 23.49, 93.71, 6.83, 191.78),\n (38, 68, 54, 29.34, 90.82, 6.74, 202.06),\n (69, 64, 47, 40.21, 94.51, 6.99, 186.68),\n (58, 51, 47, 42.13, 91.7, 6.76, 197.4),\n (59, 47, 53, 32.86, 91.46, 6.85, 47.27),\n (44, 64, 54, 29.81, 91.38, 6.74, 232.7),\n (56, 57, 48, 31.56, 93.05, 6.51, 63.62),\n (69, 60, 54, 36.32, 93.06, 6.99, 141.17),\n (56, 58, 49, 37.13, 94.61, 6.69, 172.48),\n (49, 55, 53, 38.44, 93.64, 6.54, 77.72),\n (38, 51, 52, 32.66, 90.79, 6.93, 78.85),\n (54, 65, 47, 27.93, 91.56, 6.72, 149.91),\n (57, 57, 51, 39.02, 91.49, 6.99, 105.88),\n (22, 16, 27, 29.18, 90.27, 6.01, 188.93),\n (58, 67, 45, 38.72, 91.73, 6.7, 62.62),\n (61, 64, 52, 43.3, 92.83, 6.64, 110.56),\n (34, 62, 55, 27.59, 90.73, 6.59, 238.5),\n (31, 48, 45, 40.79, 92.91, 6.56, 132.79),\n (47, 46, 52, 23.19, 91.4, 6.5, 206.4),\n (40, 120, 197, 23.81, 92.49, 5.89, 248.86),\n (36, 59, 46, 34.29, 93.61, 6.72, 127.25),\n (61, 51, 51, 39.3, 94.16, 6.57, 120.95),\n (70, 54, 46, 39.73, 91.12, 6.92, 122.76),\n (44, 56, 49, 39.23, 91.26, 6.52, 64.45),\n (34, 68, 51, 27.35, 94.18, 6.69, 40.35),\n (50, 59, 47, 40.77, 92.09, 6.75, 209.87),\n (39, 70, 52, 26.27, 90.8, 6.65, 59.49),\n (34, 61, 49, 28.13, 93.32, 6.5, 117.82),\n (44, 60, 55, 34.28, 90.56, 6.83, 98.54),\n (31, 62, 52, 33.8, 93.01, 6.99, 182.03),\n (65, 62, 51, 31.53, 90.87, 6.51, 207.07),\n (44, 57, 53, 42.3, 90.51, 6.93, 74.88),\n (50, 47, 48, 24.64, 90.62, 6.71, 218.23),\n (43, 50, 48, 28.28, 91.37, 6.63, 179.27),\n (60, 46, 53, 24.49, 92.98, 6.76, 183.49),\n (70, 68, 55, 42.85, 94.64, 6.69, 78.81),\n (59, 62, 52, 43.68, 93.11, 6.61, 103.82),\n (60, 58, 51, 42.07, 92.92, 6.84, 165.74),\n (42, 60, 47, 33.47, 92.13, 6.83, 136.83),\n (35, 66, 47, 31.7, 91.66, 6.95, 48.84),\n (34, 65, 48, 41.42, 90.04, 6.67, 199.31),\n (36, 54, 46, 42.55, 94.94, 6.66, 214.41),\n (39, 64, 52, 28.92, 94.64, 6.68, 63.69),\n (37, 52, 47, 43.08, 93.9, 6.54, 211.85),\n (33, 47, 46, 29.2, 93.97, 6.84, 209.41),\n (34, 48, 48, 41.04, 91.37, 6.81, 181.53),\n (49, 54, 50, 25.62, 93.18, 6.76, 97.26),\n (40, 65, 49, 35.33, 91.06, 6.68, 163.91),\n (68, 52, 49, 24.43, 92.28, 6.58, 63.35),\n (50, 46, 52, 31.18, 90.22, 6.73, 54.02),\n (65, 63, 50, 31.88, 91.33, 6.52, 79.27),\n (40, 49, 47, 42.93, 91.18, 6.5, 246.36),\n (42, 53, 48, 23.11, 94.32, 6.76, 231.52),\n (49, 55, 51, 24.87, 93.91, 6.68, 135.17),\n (59, 62, 49, 43.36, 93.35, 6.94, 114.78),\n (63, 58, 47, 26.83, 90.75, 6.86, 144.67),\n (70, 65, 52, 30.42, 93.13, 6.58, 75.95),\n (63, 50, 52, 28.65, 93.23, 6.75, 115.82),\n (0, 19, 31, 25.52, 94.38, 6.27, 71.74),\n (63, 58, 50, 43.04, 94.64, 6.72, 41.59),\n (45, 58, 49, 30.11, 90.35, 6.83, 75.25),\n (66, 69, 47, 23.69, 93.61, 6.91, 87.53),\n (54, 67, 52, 35.68, 93.31, 6.59, 141.34),\n (69, 67, 52, 27.72, 94.44, 6.83, 82.83),\n (67, 68, 49, 35.27, 92.38, 6.82, 149.85),\n (45, 57, 47, 23.17, 90.79, 6.66, 161.69),\n (56, 50, 52, 33.09, 92.25, 6.77, 88.13),\n (70, 50, 53, 37.46, 90.45, 6.93, 172.35),\n (40, 120, 197, 23.81, 92.49, 5.89, 218.14),\n (50, 60, 47, 32.58, 92.75, 6.93, 93.79),\n (52, 51, 53, 38.38, 93.1, 6.99, 210.27),\n (35, 68, 45, 42.94, 90.09, 6.61, 234.85),\n (68, 69, 52, 25.65, 92.75, 6.81, 52.95),\n (32, 55, 52, 37.59, 92.0, 6.97, 159.66),\n (32, 55, 51, 29.61, 93.16, 6.57, 62.69),\n (29, 17, 29, 29.2, 95.67, 5.96, 174.4),\n (29, 17, 29, 29.2, 95.67, 5.96, 241.82),\n (49, 61, 45, 32.77, 94.57, 6.76, 240.48),\n (48, 57, 54, 29.02, 90.2, 6.62, 126.81),\n (69, 66, 49, 40.0, 90.17, 6.53, 92.12),\n (53, 55, 55, 33.32, 91.25, 6.71, 234.5),\n (38, 61, 52, 31.23, 94.94, 6.62, 46.44),\n (57, 64, 55, 26.68, 92.96, 6.58, 62.51),\n (51, 57, 55, 24.71, 90.15, 6.68, 108.41),\n (56, 65, 45, 38.2, 93.97, 6.75, 218.09),\n (54, 66, 52, 36.57, 93.8, 6.87, 104.42),\n (58, 55, 47, 26.05, 93.69, 6.74, 240.69),\n (68, 70, 54, 31.3, 92.76, 6.99, 54.78),\n (42, 59, 55, 40.1, 94.35, 6.98, 149.12),\n (43, 64, 47, 38.59, 91.58, 6.83, 102.27),\n (35, 67, 49, 41.31, 91.15, 6.62, 239.74),\n (56, 59, 55, 37.04, 91.79, 6.55, 188.52),\n (39, 64, 53, 23.01, 91.07, 6.6, 208.34),\n (18, 30, 29, 26.76, 92.86, 6.42, 224.59),\n (37, 23, 28, 25.61, 94.31, 5.74, 224.32),\n (13, 28, 33, 28.13, 95.65, 5.69, 151.08),\n (2, 21, 35, 25.03, 91.54, 6.29, 179.82),\n (10, 18, 35, 27.8, 99.65, 6.38, 181.69),\n (7, 11, 32, 29.26, 95.11, 5.54, 184.76),\n (39, 5, 31, 27.1, 93.7, 5.55, 150.95),\n (34, 6, 27, 25.85, 90.93, 5.86, 147.89),\n (31, 30, 29, 26.59, 90.99, 5.56, 178.81),\n (25, 7, 35, 28.39, 99.19, 5.56, 189.67),\n (16, 18, 26, 28.44, 91.81, 5.57, 145.54),\n (26, 10, 33, 28.27, 96.94, 6.07, 198.82),\n (27, 8, 32, 27.01, 96.46, 5.63, 144.33),\n (37, 18, 30, 27.64, 99.35, 6.38, 157.92),\n (19, 15, 34, 26.3, 99.66, 5.69, 215.92),\n (0, 19, 33, 27.13, 95.24, 6.23, 204.72),\n (31, 20, 26, 25.57, 97.61, 6.44, 199.79),\n (9, 17, 32, 25.95, 93.41, 5.84, 172.05),\n (22, 11, 29, 28.03, 95.02, 5.96, 218.01),\n (31, 6, 26, 29.13, 91.31, 5.74, 157.24),\n (34, 6, 30, 27.08, 97.0, 5.95, 171.76),\n (24, 6, 32, 28.11, 90.02, 6.39, 172.48),\n (1, 8, 26, 27.51, 94.19, 5.56, 156.67),\n (31, 13, 33, 27.64, 95.49, 5.86, 205.55),\n (10, 9, 28, 29.01, 94.01, 6.28, 150.05),\n (36, 27, 26, 26.58, 95.79, 6.25, 171.63),\n (38, 24, 33, 28.29, 97.0, 5.97, 142.94),\n (11, 6, 25, 28.69, 96.65, 6.08, 178.96),\n (16, 14, 30, 29.71, 96.3, 6.37, 209.85),\n (33, 14, 35, 27.15, 96.66, 6.03, 149.24),\n (16, 6, 29, 29.29, 91.96, 5.87, 132.15),\n (32, 11, 31, 25.07, 93.31, 6.21, 134.84),\n (38, 14, 30, 26.92, 91.2, 5.57, 194.9),\n (8, 6, 33, 28.28, 93.65, 6.1, 171.95),\n (23, 6, 33, 29.18, 92.73, 6.03, 204.96),\n (29, 25, 35, 28.36, 91.65, 5.54, 160.73),\n (24, 14, 33, 29.38, 93.28, 6.37, 218.52),\n (32, 12, 30, 25.39, 98.09, 5.58, 218.08),\n (30, 25, 31, 26.31, 98.62, 5.8, 208.12),\n (14, 21, 35, 29.53, 91.91, 6.12, 194.31),\n (27, 22, 29, 28.83, 92.17, 6.0, 145.42),\n (40, 5, 29, 28.48, 97.77, 5.82, 160.39),\n (17, 11, 32, 28.74, 93.4, 5.62, 156.77),\n (30, 30, 35, 25.01, 95.59, 6.0, 165.81),\n (28, 10, 30, 29.87, 91.15, 6.31, 192.77),\n (39, 7, 29, 27.54, 94.59, 6.36, 150.2),\n (32, 20, 35, 26.52, 98.38, 5.59, 144.63),\n (7, 15, 32, 25.04, 95.9, 6.18, 174.8),\n (29, 17, 29, 29.2, 95.67, 5.96, 211.25),\n (34, 15, 34, 27.06, 91.11, 5.68, 224.7),\n (14, 23, 25, 26.19, 96.97, 5.61, 135.42),\n (18, 19, 29, 27.59, 92.49, 6.21, 162.84),\n (7, 21, 35, 25.76, 94.66, 5.76, 131.25),\n (24, 27, 34, 28.88, 95.11, 6.2, 145.06),\n (39, 29, 29, 26.51, 94.48, 6.14, 199.88),\n (29, 8, 28, 26.87, 91.73, 6.1, 214.41),\n (10, 24, 27, 27.57, 94.9, 5.71, 145.93),\n (0, 29, 32, 28.06, 98.37, 5.87, 171.65),\n (32, 11, 31, 29.52, 92.56, 6.46, 131.21),\n (37, 10, 32, 28.96, 95.16, 6.17, 222.8),\n (20, 29, 27, 25.1, 92.36, 6.05, 157.76),\n (31, 29, 35, 27.19, 92.2, 6.14, 141.32),\n (17, 30, 27, 29.03, 90.79, 5.89, 205.57),\n (1, 12, 30, 27.75, 95.95, 5.56, 131.09),\n (6, 13, 29, 27.31, 99.97, 5.83, 201.83),\n (15, 28, 32, 28.84, 99.64, 6.22, 224.4),\n (27, 24, 29, 26.61, 96.97, 6.14, 191.01),\n (3, 23, 30, 29.7, 95.66, 6.08, 215.2),\n (8, 26, 26, 25.55, 91.64, 5.7, 212.87),\n (20, 28, 26, 26.38, 91.5, 5.55, 167.05),\n (26, 18, 27, 27.46, 92.91, 5.84, 142.14),\n (1, 6, 35, 27.02, 95.72, 6.23, 147.17),\n (27, 30, 31, 28.99, 90.74, 5.72, 148.84),\n (23, 7, 34, 26.11, 91.52, 5.85, 134.13),\n (0, 26, 31, 25.07, 95.02, 5.55, 192.9),\n (38, 6, 25, 25.55, 96.93, 6.16, 191.3),\n (25, 12, 26, 28.57, 95.68, 6.44, 134.84),\n (40, 5, 32, 26.07, 96.7, 5.98, 143.53),\n (0, 19, 31, 25.52, 94.38, 6.27, 178.73),\n (26, 9, 32, 25.95, 94.74, 6.47, 144.16),\n (35, 30, 34, 28.3, 95.41, 6.14, 182.45),\n (19, 30, 30, 29.57, 91.41, 5.83, 224.83),\n (31, 13, 33, 29.7, 95.21, 6.34, 148.3),\n (17, 29, 26, 26.14, 93.28, 6.07, 195.41),\n (2, 30, 30, 26.0, 94.8, 6.33, 209.54),\n (30, 13, 25, 27.15, 91.49, 6.41, 164.92),\n (8, 15, 33, 28.97, 98.1, 5.5, 213.9),\n (18, 12, 35, 26.14, 96.39, 6.34, 131.34),\n (8, 28, 30, 25.52, 94.33, 6.02, 135.13),\n (40, 22, 29, 27.56, 99.98, 5.74, 174.63),\n (27, 10, 33, 27.81, 97.48, 6.47, 154.06),\n (21, 20, 31, 25.6, 99.72, 5.86, 165.82),\n (3, 9, 35, 26.92, 99.85, 6.32, 225.63),\n (22, 16, 27, 29.18, 90.27, 6.01, 188.93),\n (27, 8, 30, 26.45, 98.3, 6.01, 221.23),\n (22, 8, 33, 28.44, 95.88, 5.67, 203.93),\n (28, 27, 32, 28.94, 93.0, 5.76, 191.77),\n (23, 21, 26, 26.45, 93.45, 5.9, 149.22),\n (37, 5, 34, 25.79, 93.84, 5.78, 152.42),\n (19, 26, 29, 26.93, 98.8, 5.67, 166.57),\n ...]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_names"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T09:49:35.709872600Z",
     "start_time": "2024-03-20T09:49:35.689583Z"
    }
   },
   "id": "5ad60d8bef9fe14c",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('pomegranate',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('banana',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('mango',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('grapes',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('watermelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('muskmelon',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('apple',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('orange',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('papaya',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ('coconut',),\n ...]"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T09:49:37.559037400Z",
     "start_time": "2024-03-20T09:49:37.526906400Z"
    }
   },
   "id": "e85f28b3dfc1f246",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T09:49:39.739403400Z",
     "start_time": "2024-03-20T09:49:38.824998900Z"
    }
   },
   "id": "55c1179bd8859db7",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "Xtrain,Xtest,Ytrain,Ytest = train_test_split(model_names,target,test_size = 0.2,random_state = 2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T09:49:39.944519500Z",
     "start_time": "2024-03-20T09:49:39.936292900Z"
    }
   },
   "id": "b1587ae2b069b368",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[(32, 121, 199, 39.37, 81.25, 6.13, 74.08),\n (92, 85, 51, 29.22, 81.08, 5.74, 108.86),\n (81, 18, 50, 26.44, 80.92, 6.51, 47.82),\n (9, 8, 15, 14.34, 94.36, 7.99, 110.22),\n (21, 9, 40, 24.51, 90.64, 5.96, 105.62),\n (95, 75, 50, 28.08, 75.26, 5.62, 73.7),\n (95, 26, 45, 29.92, 94.56, 6.12, 28.16),\n (80, 90, 47, 26.6, 79.36, 6.21, 107.39),\n (21, 134, 202, 10.72, 80.02, 6.43, 65.3),\n (24, 33, 35, 29.26, 54.82, 5.34, 100.76),\n (36, 24, 41, 24.94, 94.26, 7.01, 103.88),\n (7, 16, 9, 18.88, 92.04, 7.81, 114.67),\n (34, 11, 10, 31.75, 94.6, 7.36, 115.2),\n (114, 8, 52, 29.34, 94.55, 6.42, 28.23),\n (9, 10, 10, 22.36, 93.52, 6.01, 101.52),\n (13, 16, 8, 34.74, 93.12, 6.95, 100.2),\n (22, 17, 26, 28.7, 47.72, 4.75, 99.64),\n (94, 5, 55, 28.59, 91.89, 6.09, 26.88),\n (82, 78, 46, 25.06, 84.97, 5.74, 110.44),\n (54, 65, 47, 27.93, 91.56, 6.72, 149.91),\n (27, 22, 29, 28.83, 92.17, 6.0, 145.42),\n (19, 15, 34, 26.3, 99.66, 5.69, 215.92),\n (28, 123, 202, 22.77, 92.12, 6.44, 120.44),\n (40, 9, 41, 24.38, 85.4, 5.78, 106.13),\n (38, 14, 37, 21.81, 94.64, 6.66, 102.65),\n (88, 78, 45, 29.1, 79.2, 6.32, 92.08),\n (2, 140, 197, 22.7, 92.82, 5.53, 105.05),\n (95, 75, 50, 28.08, 75.26, 5.62, 110.71),\n (8, 139, 199, 29.37, 81.54, 6.34, 66.13),\n (81, 18, 50, 26.81, 88.23, 6.43, 58.8),\n (11, 36, 31, 27.92, 51.78, 6.48, 100.26),\n (25, 27, 41, 19.2, 94.28, 6.92, 112.4),\n (105, 88, 54, 25.79, 84.51, 6.02, 114.2),\n (104, 23, 47, 26.98, 86.7, 6.77, 42.91),\n (28, 37, 28, 32.13, 50.53, 6.1, 98.63),\n (35, 138, 200, 21.2, 90.81, 5.67, 103.68),\n (40, 18, 43, 19.39, 86.79, 5.77, 109.91),\n (8, 33, 29, 29.98, 49.49, 6.44, 91.82),\n (26, 126, 195, 21.41, 92.99, 5.88, 118.4),\n (113, 30, 50, 26.04, 83.99, 6.28, 43.88),\n (13, 5, 8, 23.85, 90.11, 7.47, 103.92),\n (21, 26, 27, 27.0, 47.68, 5.7, 95.85),\n (14, 139, 197, 21.72, 92.84, 6.06, 121.7),\n (58, 51, 47, 42.13, 91.7, 6.76, 197.4),\n (35, 30, 34, 28.3, 95.41, 6.14, 182.45),\n (108, 23, 51, 26.84, 83.85, 6.11, 40.23),\n (37, 126, 196, 23.6, 90.98, 5.6, 107.17),\n (32, 121, 199, 39.37, 81.25, 6.13, 74.08),\n (85, 89, 51, 29.21, 84.7, 6.16, 108.55),\n (1, 124, 199, 23.71, 93.27, 5.66, 112.67),\n (114, 27, 48, 27.82, 93.04, 6.53, 26.32),\n (83, 15, 49, 28.93, 91.39, 6.44, 23.2),\n (114, 21, 55, 25.44, 87.94, 6.47, 57.52),\n (69, 66, 49, 40.0, 90.17, 6.53, 92.12),\n (36, 29, 13, 20.68, 90.92, 7.83, 109.75),\n (1, 135, 203, 22.78, 92.7, 5.62, 113.78),\n (37, 6, 13, 26.03, 91.51, 7.51, 101.28),\n (22, 18, 33, 30.41, 52.48, 6.62, 93.92),\n (12, 20, 39, 19.86, 86.2, 6.03, 111.02),\n (34, 34, 35, 27.27, 47.17, 6.42, 95.26),\n (90, 92, 55, 27.01, 80.19, 6.13, 97.33),\n (22, 11, 29, 28.03, 95.02, 5.96, 218.01),\n (39, 30, 38, 20.13, 87.6, 6.97, 108.07),\n (56, 50, 52, 33.09, 92.25, 6.77, 88.13),\n (81, 16, 45, 26.9, 86.25, 6.73, 59.76),\n (12, 31, 26, 35.79, 51.94, 5.4, 100.22),\n (33, 14, 35, 27.15, 96.66, 6.03, 149.24),\n (9, 17, 32, 25.95, 93.41, 5.84, 172.05),\n (106, 70, 55, 25.87, 78.52, 5.74, 116.3),\n (26, 24, 34, 31.27, 52.24, 6.81, 89.74),\n (111, 15, 54, 27.71, 92.91, 6.19, 22.06),\n (27, 8, 32, 27.01, 96.46, 5.63, 144.33),\n (113, 28, 48, 28.88, 92.49, 6.17, 24.44),\n (103, 72, 51, 26.13, 81.81, 6.1, 104.48),\n (40, 5, 32, 26.07, 96.7, 5.98, 143.53),\n (29, 22, 43, 19.66, 87.95, 5.56, 106.04),\n (21, 135, 198, 23.86, 94.92, 5.77, 105.02),\n (36, 24, 41, 24.94, 94.26, 7.01, 103.88),\n (16, 18, 26, 28.44, 91.81, 5.57, 145.54),\n (49, 61, 45, 32.77, 94.57, 6.76, 240.48),\n (0, 12, 7, 20.18, 90.65, 6.97, 116.81),\n (28, 130, 196, 22.13, 94.68, 6.06, 112.92),\n (80, 18, 51, 28.05, 91.82, 6.71, 20.77),\n (40, 24, 25, 28.71, 50.44, 5.45, 95.89),\n (24, 18, 6, 26.57, 94.45, 6.29, 116.38),\n (3, 141, 197, 21.98, 91.13, 6.14, 115.48),\n (37, 18, 39, 24.15, 94.51, 6.42, 110.23),\n (39, 29, 29, 26.51, 94.48, 6.14, 199.88),\n (34, 65, 47, 23.49, 93.71, 6.83, 191.78),\n (32, 141, 203, 21.26, 92.84, 5.82, 109.07),\n (27, 10, 33, 27.81, 97.48, 6.47, 154.06),\n (2, 30, 30, 26.0, 94.8, 6.33, 209.54),\n (27, 120, 200, 21.45, 90.75, 6.11, 116.7),\n (33, 139, 203, 33.34, 82.51, 5.69, 70.68),\n (23, 142, 197, 39.07, 82.04, 6.0, 69.31),\n (37, 18, 12, 10.27, 90.19, 7.4, 106.7),\n (88, 5, 47, 25.86, 86.67, 6.66, 41.17),\n (106, 21, 52, 28.9, 94.79, 6.29, 23.04),\n (10, 140, 197, 22.17, 90.27, 6.23, 124.47),\n (0, 123, 205, 22.03, 92.96, 5.79, 121.13),\n (97, 12, 47, 25.29, 89.64, 6.77, 58.29),\n (24, 142, 202, 22.54, 91.48, 5.71, 101.85),\n (117, 19, 55, 28.8, 91.78, 6.12, 25.16),\n (14, 128, 205, 22.61, 94.59, 6.23, 116.04),\n (5, 29, 44, 21.02, 93.06, 5.58, 104.78),\n (3, 23, 30, 29.7, 95.66, 6.08, 215.2),\n (108, 88, 55, 26.29, 83.39, 5.89, 113.87),\n (15, 11, 38, 23.13, 92.68, 6.63, 109.39),\n (95, 23, 45, 27.82, 90.57, 6.27, 21.19),\n (95, 12, 51, 25.76, 84.17, 6.68, 44.22),\n (33, 29, 34, 31.41, 49.22, 6.83, 93.0),\n (117, 76, 47, 25.56, 77.38, 6.12, 93.1),\n (99, 5, 47, 24.13, 84.84, 6.65, 51.19),\n (102, 73, 52, 27.91, 83.36, 6.36, 90.24),\n (101, 17, 47, 29.49, 94.73, 6.19, 26.31),\n (11, 124, 204, 13.43, 80.07, 6.36, 71.4),\n (30, 143, 199, 23.77, 90.6, 5.8, 102.26),\n (1, 135, 203, 22.78, 92.7, 5.62, 57.45),\n (26, 126, 195, 21.41, 92.99, 5.88, 118.4),\n (15, 140, 195, 13.29, 83.54, 5.7, 65.8),\n (6, 13, 29, 27.31, 99.97, 5.83, 201.83),\n (22, 30, 12, 15.78, 92.51, 6.35, 119.04),\n (95, 12, 51, 25.76, 84.17, 6.68, 44.22),\n (113, 6, 52, 27.76, 90.36, 6.74, 25.22),\n (40, 132, 202, 24.58, 80.71, 5.97, 69.71),\n (80, 18, 51, 28.05, 91.82, 6.71, 20.77),\n (118, 18, 52, 28.05, 90.83, 6.56, 20.76),\n (2, 143, 196, 22.71, 90.45, 5.67, 109.89),\n (15, 125, 199, 18.43, 80.56, 5.57, 69.76),\n (59, 62, 52, 43.68, 93.11, 6.61, 103.82),\n (83, 94, 47, 27.4, 81.11, 6.47, 112.14),\n (20, 20, 10, 11.87, 93.68, 6.98, 106.06),\n (13, 16, 8, 34.74, 93.12, 6.95, 100.2),\n (0, 19, 31, 25.52, 94.38, 6.27, 178.73),\n (0, 27, 38, 22.45, 89.9, 6.74, 109.39),\n (50, 47, 48, 24.64, 90.62, 6.71, 218.23),\n (37, 124, 195, 18.71, 83.48, 6.21, 66.6),\n (85, 21, 52, 29.63, 90.1, 6.08, 23.7),\n (103, 17, 51, 25.11, 80.03, 6.21, 44.21),\n (29, 121, 196, 22.85, 94.32, 6.08, 123.6),\n (26, 10, 33, 28.27, 96.94, 6.07, 198.82),\n (31, 30, 29, 26.59, 90.99, 5.56, 104.9),\n (66, 69, 47, 23.69, 93.61, 6.91, 87.53),\n (100, 76, 45, 25.57, 75.94, 5.59, 102.79),\n (108, 88, 55, 26.29, 83.39, 5.89, 113.87),\n (7, 144, 197, 23.85, 94.35, 6.13, 114.05),\n (22, 18, 31, 30.76, 47.94, 5.96, 90.39),\n (5, 29, 44, 21.02, 93.06, 5.58, 104.78),\n (89, 25, 50, 27.05, 91.35, 6.38, 25.08),\n (36, 133, 198, 25.52, 83.98, 6.23, 69.17),\n (115, 12, 52, 27.51, 94.96, 6.69, 21.02),\n (6, 142, 202, 27.24, 82.95, 6.22, 70.43),\n (56, 65, 45, 38.2, 93.97, 6.75, 218.09),\n (34, 61, 49, 28.13, 93.32, 6.5, 117.82),\n (37, 135, 205, 11.83, 80.28, 5.51, 74.1),\n (31, 62, 52, 33.8, 93.01, 6.99, 182.03),\n (10, 5, 5, 21.21, 91.35, 7.82, 112.98),\n (87, 6, 45, 29.83, 90.79, 6.4, 22.84),\n (101, 17, 55, 24.37, 87.13, 6.45, 44.64),\n (8, 28, 38, 23.23, 94.43, 6.84, 105.69),\n (10, 5, 42, 20.24, 91.09, 6.89, 109.25),\n (59, 62, 49, 43.36, 93.35, 6.94, 114.78),\n (5, 8, 5, 11.03, 92.23, 6.56, 112.77),\n (36, 11, 13, 17.34, 93.05, 7.19, 112.72),\n (33, 23, 45, 20.0, 85.84, 7.12, 112.34),\n (6, 144, 198, 21.11, 90.32, 5.56, 104.51),\n (89, 9, 47, 29.47, 90.77, 6.67, 28.75),\n (32, 141, 204, 8.83, 82.9, 5.54, 67.24),\n (3, 28, 33, 30.34, 48.89, 5.76, 94.43),\n (68, 52, 49, 24.43, 92.28, 6.58, 63.35),\n (109, 12, 48, 29.46, 92.13, 6.71, 20.76),\n (23, 5, 44, 21.21, 94.26, 7.16, 107.57),\n (29, 34, 26, 33.88, 54.39, 6.27, 89.29),\n (2, 24, 38, 24.56, 91.64, 5.92, 111.97),\n (116, 25, 50, 29.26, 92.92, 6.09, 28.71),\n (33, 143, 204, 21.13, 91.96, 5.81, 122.54),\n (37, 23, 28, 25.61, 94.31, 5.74, 224.32),\n (38, 19, 31, 34.74, 49.09, 5.86, 90.65),\n (120, 23, 55, 27.84, 91.61, 6.73, 26.48),\n (50, 46, 52, 31.18, 90.22, 6.73, 54.02),\n (3, 26, 39, 24.38, 91.19, 7.08, 103.6),\n (11, 143, 197, 22.98, 93.32, 5.88, 122.2),\n (100, 6, 53, 29.05, 93.92, 6.11, 23.67),\n (37, 38, 32, 31.86, 45.53, 5.42, 91.56),\n (16, 8, 9, 24.6, 91.28, 7.6, 111.29),\n (70, 54, 46, 39.73, 91.12, 6.92, 122.76),\n (25, 12, 26, 28.57, 95.68, 6.44, 134.84),\n (13, 121, 196, 22.21, 93.51, 6.44, 120.16),\n (26, 32, 32, 30.91, 49.93, 6.81, 90.14),\n (111, 88, 55, 29.45, 78.35, 5.51, 96.45),\n (38, 24, 33, 28.29, 97.0, 5.97, 142.94),\n (26, 18, 30, 32.06, 51.08, 6.34, 96.6),\n (94, 91, 51, 29.16, 76.67, 5.62, 109.58),\n (117, 24, 53, 29.17, 92.21, 6.29, 21.3),\n (8, 37, 33, 28.08, 54.96, 6.13, 97.45),\n (38, 14, 30, 26.92, 91.2, 5.57, 194.9),\n (38, 132, 197, 20.42, 81.54, 5.93, 66.93),\n (25, 121, 201, 30.51, 82.72, 5.59, 70.08),\n (14, 29, 32, 35.64, 48.97, 6.94, 97.52),\n (20, 19, 35, 34.18, 50.62, 6.11, 98.01),\n (0, 36, 26, 34.13, 51.26, 5.1, 96.39),\n (14, 22, 9, 17.25, 91.14, 6.54, 112.51),\n (86, 79, 45, 27.81, 82.69, 5.81, 99.21),\n (91, 21, 50, 24.34, 81.44, 6.76, 48.32),\n (37, 18, 39, 24.15, 94.51, 6.42, 110.23),\n (21, 137, 196, 23.61, 91.7, 5.81, 123.59),\n (31, 25, 38, 24.96, 92.41, 6.5, 109.42),\n (115, 17, 55, 27.58, 94.12, 6.78, 28.08),\n (97, 22, 50, 26.26, 86.15, 6.77, 58.98),\n (111, 5, 47, 28.03, 91.47, 6.27, 21.18),\n (119, 5, 55, 29.69, 94.3, 6.17, 26.84),\n (39, 127, 202, 15.32, 81.67, 6.48, 71.6),\n (37, 5, 34, 25.79, 93.84, 5.78, 152.42),\n (39, 29, 29, 26.51, 94.48, 6.14, 199.88),\n (33, 120, 205, 35.12, 82.27, 5.55, 69.72),\n (22, 138, 195, 27.83, 83.51, 6.21, 73.03),\n (105, 14, 50, 26.21, 87.69, 6.42, 59.66),\n (93, 20, 50, 29.93, 93.23, 6.45, 24.35),\n (10, 9, 28, 29.01, 94.01, 6.28, 150.05),\n (39, 138, 203, 21.19, 82.33, 6.4, 74.63),\n (92, 81, 52, 28.01, 76.53, 5.89, 103.7),\n (104, 23, 47, 26.98, 86.7, 6.77, 42.91),\n (36, 19, 32, 27.11, 50.71, 4.94, 92.37),\n (2, 40, 27, 29.74, 47.55, 5.95, 90.1),\n (29, 17, 29, 29.2, 95.67, 5.96, 174.4),\n (1, 15, 9, 29.98, 94.55, 7.53, 115.36),\n (21, 26, 27, 27.0, 47.68, 5.7, 95.85),\n (99, 92, 47, 28.13, 77.48, 6.32, 103.5),\n (27, 120, 200, 21.45, 90.75, 6.11, 116.7),\n (39, 138, 203, 21.19, 82.33, 6.4, 74.63),\n (70, 50, 53, 37.46, 90.45, 6.93, 172.35),\n (20, 30, 27, 27.81, 51.59, 4.75, 95.9),\n (37, 137, 199, 22.64, 90.18, 5.7, 108.34),\n (35, 66, 47, 31.7, 91.66, 6.95, 48.84),\n (31, 30, 29, 26.59, 90.99, 5.56, 104.9),\n (70, 65, 52, 30.42, 93.13, 6.58, 75.95),\n (95, 75, 50, 28.08, 75.26, 5.62, 50.79),\n (0, 23, 15, 22.57, 93.37, 7.6, 109.86),\n (19, 120, 195, 18.74, 81.12, 5.93, 73.56),\n (14, 25, 40, 20.07, 90.98, 6.41, 103.71),\n (17, 16, 14, 16.4, 92.18, 6.63, 102.94),\n (19, 123, 200, 34.76, 81.04, 6.17, 65.7),\n (1, 132, 200, 16.28, 82.94, 5.62, 66.57),\n (1, 17, 6, 10.79, 91.38, 6.82, 117.53),\n (29, 25, 14, 30.49, 90.46, 7.78, 113.33),\n (31, 13, 33, 27.64, 95.49, 5.86, 205.55),\n (12, 29, 13, 22.46, 91.53, 7.57, 118.01),\n (90, 23, 54, 28.56, 90.46, 6.16, 27.27),\n (38, 135, 203, 41.36, 82.8, 6.44, 69.92),\n (59, 62, 49, 43.36, 93.35, 6.94, 114.78),\n (89, 91, 55, 25.08, 80.26, 6.28, 94.33),\n (82, 25, 51, 24.31, 87.47, 6.07, 48.11),\n (34, 133, 202, 15.31, 80.1, 5.8, 74.82),\n (84, 29, 49, 29.94, 93.91, 6.25, 20.39),\n (80, 77, 49, 26.05, 79.4, 5.52, 113.23),\n (106, 21, 52, 28.9, 94.79, 6.29, 23.04),\n (90, 86, 52, 25.85, 81.96, 5.79, 119.09),\n (82, 13, 52, 27.12, 94.87, 6.44, 26.52),\n (20, 29, 27, 25.1, 92.36, 6.05, 157.76),\n (58, 51, 47, 42.13, 91.7, 6.76, 197.4),\n (20, 8, 12, 25.3, 94.96, 7.26, 117.97),\n (24, 128, 196, 22.75, 90.69, 5.52, 110.43),\n (31, 144, 202, 11.02, 80.56, 5.87, 68.24),\n (36, 144, 196, 23.65, 94.51, 6.5, 115.36),\n (1, 124, 199, 23.71, 93.27, 5.66, 115.57),\n (66, 69, 47, 23.69, 93.61, 6.91, 87.53),\n (70, 68, 55, 42.85, 94.64, 6.69, 78.81),\n (8, 38, 32, 29.75, 46.74, 4.98, 91.41),\n (39, 139, 201, 41.19, 81.02, 5.54, 68.69),\n (114, 8, 52, 29.34, 94.55, 6.42, 28.23),\n (95, 75, 50, 28.08, 75.26, 5.62, 93.3),\n (8, 127, 196, 27.03, 83.17, 5.83, 70.96),\n (0, 137, 195, 22.44, 80.19, 6.33, 65.4),\n (29, 8, 28, 26.87, 91.73, 6.1, 214.41),\n (24, 6, 32, 28.11, 90.02, 6.39, 172.48),\n (5, 24, 40, 24.69, 93.87, 6.3, 104.67),\n (24, 27, 9, 18.87, 93.25, 6.16, 119.39),\n (19, 15, 34, 26.3, 99.66, 5.69, 215.92),\n (12, 27, 26, 29.09, 45.57, 5.32, 96.24),\n (102, 73, 52, 27.91, 83.36, 6.36, 90.24),\n (95, 12, 46, 26.22, 81.01, 6.32, 54.65),\n (4, 19, 42, 23.83, 87.84, 6.31, 111.22),\n (29, 128, 198, 22.44, 92.71, 5.69, 121.5),\n (115, 17, 55, 27.58, 94.12, 6.78, 28.08),\n (35, 140, 197, 16.78, 82.75, 6.11, 66.76),\n (40, 21, 8, 34.91, 92.88, 7.42, 102.19),\n (22, 16, 27, 29.18, 90.27, 6.01, 188.93),\n (21, 139, 201, 19.36, 83.36, 5.98, 67.15),\n (118, 18, 52, 28.05, 90.83, 6.56, 20.76),\n (40, 120, 197, 23.81, 92.49, 5.89, 119.63),\n (92, 75, 45, 29.01, 77.95, 5.67, 90.43),\n (39, 21, 9, 13.21, 94.03, 6.35, 106.27),\n (15, 140, 195, 13.29, 83.54, 5.7, 65.8),\n (36, 54, 46, 42.55, 94.94, 6.66, 214.41),\n (36, 133, 198, 25.52, 83.98, 6.23, 69.17),\n (19, 24, 15, 20.49, 93.72, 7.14, 111.84),\n (29, 25, 35, 28.36, 91.65, 5.54, 160.73),\n (31, 5, 14, 17.67, 91.7, 6.58, 110.69),\n (83, 11, 53, 29.54, 92.92, 6.16, 21.97),\n (94, 89, 48, 28.56, 84.52, 5.65, 111.08),\n (106, 85, 53, 27.2, 78.81, 5.92, 99.72),\n (49, 55, 53, 38.44, 93.64, 6.54, 77.72),\n (27, 139, 205, 22.48, 93.41, 5.77, 105.55),\n (27, 30, 31, 28.99, 90.74, 5.72, 148.84),\n (7, 141, 195, 23.88, 93.45, 5.51, 104.91),\n (57, 57, 51, 39.02, 91.49, 6.99, 105.88),\n (56, 57, 48, 31.56, 93.05, 6.51, 63.62),\n (8, 16, 6, 12.23, 90.26, 7.11, 108.42),\n (22, 123, 205, 32.45, 83.89, 5.9, 68.74),\n (27, 30, 5, 32.72, 90.55, 7.66, 113.33),\n (92, 7, 48, 26.28, 86.63, 6.96, 54.39),\n (11, 10, 45, 22.63, 88.46, 6.4, 109.04),\n (36, 19, 32, 27.11, 50.71, 4.94, 92.37),\n (37, 18, 12, 10.27, 90.19, 7.4, 106.7),\n (81, 30, 48, 28.52, 92.1, 6.04, 29.87),\n (40, 121, 199, 26.18, 81.04, 6.32, 66.06),\n (19, 30, 30, 29.57, 91.41, 5.83, 224.83),\n (28, 123, 202, 22.77, 92.12, 6.44, 120.44),\n (22, 38, 31, 31.53, 53.06, 5.82, 98.57),\n (0, 5, 36, 24.35, 90.89, 6.15, 105.53),\n (22, 23, 44, 20.13, 89.32, 6.14, 107.34),\n (26, 126, 195, 21.41, 92.99, 5.88, 118.4),\n (8, 28, 37, 23.88, 86.21, 6.08, 108.31),\n (15, 9, 11, 11.55, 94.15, 7.91, 108.83),\n (23, 138, 200, 9.85, 80.23, 5.97, 68.43),\n (8, 133, 195, 20.47, 80.98, 6.46, 71.3),\n (2, 123, 198, 39.65, 82.21, 6.25, 70.4),\n (22, 138, 195, 27.83, 83.51, 6.21, 73.03),\n (12, 8, 10, 16.15, 91.44, 8.0, 107.43),\n (32, 14, 37, 22.73, 88.49, 6.83, 104.68),\n (6, 123, 203, 12.76, 81.62, 6.13, 66.78),\n (36, 27, 26, 26.58, 95.79, 6.25, 171.63),\n (95, 16, 46, 27.08, 90.14, 6.75, 24.45),\n (34, 21, 42, 18.76, 89.93, 6.65, 111.02),\n (19, 38, 26, 31.48, 48.78, 4.53, 93.17),\n (119, 25, 51, 26.47, 80.92, 6.28, 53.66),\n (9, 122, 201, 29.59, 80.92, 5.57, 68.06),\n (93, 22, 52, 26.59, 81.33, 6.93, 41.88),\n (56, 59, 55, 37.04, 91.79, 6.55, 188.52),\n (29, 132, 204, 23.09, 90.23, 6.1, 108.22),\n (47, 46, 52, 23.19, 91.4, 6.5, 206.4),\n (33, 134, 205, 21.04, 94.34, 6.09, 114.74),\n (38, 51, 52, 32.66, 90.79, 6.93, 68.69),\n (80, 71, 47, 27.51, 80.8, 6.16, 105.08),\n (102, 28, 54, 25.16, 80.28, 6.86, 55.5),\n (9, 29, 34, 29.38, 45.89, 5.73, 100.81),\n (3, 18, 31, 31.65, 48.21, 6.39, 91.1),\n (2, 30, 30, 26.0, 94.8, 6.33, 209.54),\n (39, 132, 196, 35.83, 83.33, 5.78, 73.68),\n (0, 36, 26, 34.13, 51.26, 5.1, 96.39),\n (33, 120, 205, 35.12, 82.27, 5.55, 69.72),\n (91, 24, 55, 26.27, 83.09, 6.26, 46.77),\n (7, 20, 12, 16.53, 94.77, 6.48, 110.04),\n (98, 22, 47, 29.07, 91.92, 6.34, 28.84),\n (69, 67, 52, 27.72, 94.44, 6.83, 82.83),\n (102, 71, 48, 28.65, 79.29, 5.7, 102.46),\n (4, 6, 7, 23.01, 91.12, 6.71, 112.67),\n (81, 6, 55, 24.89, 85.87, 6.11, 51.71),\n (0, 29, 32, 28.06, 98.37, 5.87, 171.65),\n (92, 81, 52, 28.01, 76.53, 5.89, 103.7),\n (43, 50, 48, 28.28, 91.37, 6.63, 179.27),\n (96, 13, 55, 29.53, 94.57, 6.7, 21.14),\n (27, 24, 29, 26.61, 96.97, 6.14, 191.01),\n (38, 135, 203, 23.76, 93.66, 5.97, 100.83),\n (68, 70, 54, 31.3, 92.76, 6.99, 54.78),\n (0, 23, 15, 22.57, 93.37, 7.6, 109.86),\n (98, 26, 49, 27.29, 90.53, 6.13, 23.5),\n (33, 47, 46, 29.2, 93.97, 6.84, 209.41),\n (4, 19, 42, 23.83, 87.84, 6.31, 111.22),\n (24, 27, 34, 28.88, 95.11, 6.2, 145.06),\n (22, 16, 27, 29.18, 90.27, 6.01, 188.93),\n (90, 16, 45, 24.92, 80.62, 6.29, 50.56),\n (14, 121, 203, 9.72, 83.75, 6.16, 74.46),\n (24, 130, 195, 30.0, 81.54, 6.11, 67.13),\n (94, 91, 51, 29.16, 76.67, 5.62, 109.58),\n (14, 18, 35, 31.09, 47.02, 4.79, 91.47),\n (80, 71, 47, 27.51, 80.8, 6.16, 105.08),\n (90, 15, 52, 27.05, 91.38, 6.45, 23.66),\n (100, 10, 53, 24.54, 84.61, 6.21, 42.01),\n (0, 133, 200, 23.67, 90.49, 5.71, 104.23),\n (61, 68, 50, 35.21, 91.5, 6.79, 243.07),\n (9, 17, 32, 25.95, 93.41, 5.84, 172.05),\n (81, 18, 50, 26.44, 80.92, 6.51, 47.82),\n (20, 23, 11, 31.85, 90.12, 6.41, 109.95),\n (9, 11, 8, 24.86, 94.39, 6.56, 111.78),\n (42, 59, 55, 40.1, 94.35, 6.98, 149.12),\n (109, 10, 53, 26.82, 87.83, 6.55, 46.06),\n (106, 10, 49, 27.73, 92.01, 6.35, 20.21),\n (28, 37, 28, 32.13, 50.53, 6.1, 98.63),\n (27, 8, 32, 27.01, 96.46, 5.63, 144.33),\n (49, 54, 50, 25.62, 93.18, 6.76, 97.26),\n (4, 6, 7, 23.01, 91.12, 6.71, 112.67),\n (43, 50, 48, 28.28, 91.37, 6.63, 179.27),\n (20, 30, 27, 27.81, 51.59, 4.75, 95.9),\n (120, 25, 50, 28.05, 94.82, 6.33, 21.85),\n (40, 144, 196, 22.72, 92.25, 5.99, 107.03),\n (34, 16, 25, 30.07, 50.96, 6.11, 92.1),\n (39, 127, 202, 15.32, 81.67, 6.48, 71.6),\n (37, 36, 26, 32.89, 52.61, 4.65, 94.49),\n (103, 72, 51, 26.13, 81.81, 6.1, 104.48),\n (31, 30, 29, 26.59, 90.99, 5.56, 178.81),\n (40, 16, 35, 31.89, 49.02, 6.48, 89.59),\n (35, 131, 203, 22.43, 93.92, 5.89, 102.72),\n (89, 25, 54, 24.69, 85.57, 6.35, 48.99),\n (9, 21, 32, 32.27, 53.56, 5.87, 95.94),\n (118, 88, 52, 28.65, 82.69, 5.84, 98.75),\n (108, 22, 47, 28.54, 91.73, 6.16, 25.13),\n (34, 62, 55, 27.59, 90.73, 6.59, 238.5),\n (95, 74, 50, 25.9, 80.47, 6.0, 110.1),\n (117, 27, 48, 26.53, 82.39, 6.84, 54.31),\n (18, 9, 40, 19.45, 89.02, 5.63, 106.16),\n (56, 58, 49, 37.13, 94.61, 6.69, 172.48),\n (13, 30, 37, 20.86, 91.62, 6.28, 106.87),\n (98, 26, 49, 27.29, 90.53, 6.13, 23.5),\n (95, 75, 50, 28.08, 75.26, 5.62, 110.71),\n (63, 50, 52, 28.65, 93.23, 6.75, 115.82),\n (25, 7, 35, 28.39, 99.19, 5.56, 189.67),\n (19, 7, 10, 14.78, 91.22, 6.12, 100.2),\n (23, 30, 44, 20.94, 85.43, 6.12, 103.03),\n (31, 26, 9, 11.7, 93.26, 7.57, 103.2),\n (13, 22, 5, 19.67, 90.5, 7.76, 100.17),\n (119, 9, 50, 26.75, 83.92, 6.25, 40.79),\n (0, 145, 205, 21.23, 90.1, 5.52, 113.98),\n (16, 139, 203, 17.83, 80.96, 6.28, 65.85),\n (111, 6, 53, 26.49, 88.59, 6.31, 46.06),\n (68, 70, 54, 31.3, 92.76, 6.99, 54.78),\n (85, 9, 53, 28.21, 92.87, 6.45, 28.79),\n (1, 30, 29, 28.33, 51.4, 6.43, 91.67),\n (38, 135, 203, 41.36, 82.8, 6.44, 69.92),\n (10, 18, 35, 27.8, 99.65, 6.38, 181.69),\n (40, 120, 197, 23.81, 92.49, 5.89, 112.54),\n (59, 47, 53, 32.86, 91.46, 6.85, 47.27),\n (113, 28, 48, 28.88, 92.49, 6.17, 24.44),\n (37, 18, 12, 10.27, 90.19, 7.4, 106.7),\n (8, 37, 33, 28.08, 54.96, 6.13, 97.45),\n (81, 6, 55, 24.89, 85.87, 6.11, 51.71),\n (8, 25, 36, 19.91, 94.95, 6.83, 104.03),\n (102, 11, 45, 29.03, 93.13, 6.36, 24.16),\n (110, 22, 47, 29.03, 91.82, 6.24, 24.94),\n (18, 30, 29, 26.76, 92.86, 6.42, 224.59),\n (23, 21, 26, 26.45, 93.45, 5.9, 149.22),\n (26, 18, 30, 32.06, 51.08, 6.34, 96.6),\n (6, 140, 205, 17.67, 82.93, 6.31, 69.87),\n (10, 5, 42, 20.24, 91.09, 6.89, 109.25),\n (103, 17, 51, 25.11, 80.03, 6.21, 44.21),\n (110, 7, 45, 26.64, 84.7, 6.19, 48.32),\n (9, 8, 15, 14.34, 94.36, 7.99, 110.22),\n (40, 27, 45, 21.66, 94.79, 5.89, 112.43),\n (26, 121, 201, 22.19, 90.03, 6.16, 112.31),\n (101, 20, 48, 24.68, 82.75, 6.21, 57.06),\n (40, 120, 197, 23.81, 92.49, 5.89, 119.63),\n (8, 7, 10, 28.26, 91.98, 6.93, 105.21),\n (32, 145, 203, 23.83, 90.84, 6.41, 109.6),\n (14, 19, 14, 17.68, 94.36, 6.7, 108.06),\n (119, 5, 55, 29.69, 94.3, 6.17, 26.84),\n (87, 14, 48, 29.69, 92.59, 6.61, 29.11),\n (22, 16, 27, 29.18, 90.27, 6.01, 188.93),\n (22, 16, 27, 29.18, 90.27, 6.01, 188.93),\n (89, 91, 55, 25.08, 80.26, 6.28, 94.33),\n (106, 14, 45, 24.47, 84.16, 6.42, 57.27),\n (31, 36, 29, 33.94, 52.72, 6.46, 97.46),\n (29, 22, 43, 19.66, 87.95, 5.56, 106.04),\n (4, 23, 5, 22.68, 93.36, 7.48, 110.33),\n (2, 36, 31, 30.9, 49.96, 5.73, 91.78),\n (49, 61, 45, 32.77, 94.57, 6.76, 240.48),\n (82, 13, 52, 27.12, 94.87, 6.44, 26.52),\n (15, 133, 199, 24.0, 91.61, 5.82, 117.61),\n (54, 66, 52, 36.57, 93.8, 6.87, 104.42),\n (111, 79, 53, 28.31, 75.77, 6.17, 119.7),\n (80, 18, 51, 28.05, 91.82, 6.71, 20.77),\n (40, 16, 35, 34.16, 54.16, 4.95, 98.33),\n (89, 85, 55, 26.67, 76.49, 6.28, 91.73),\n (5, 24, 40, 24.69, 93.87, 6.3, 104.67),\n (32, 129, 201, 16.36, 83.0, 6.49, 71.56),\n (114, 79, 51, 26.21, 82.34, 6.31, 112.07),\n (82, 13, 52, 27.12, 94.87, 6.44, 26.52),\n (17, 11, 32, 28.74, 93.4, 5.62, 156.77),\n (1, 132, 200, 16.28, 82.94, 5.62, 66.57),\n (39, 140, 203, 21.12, 80.63, 6.35, 69.28),\n (49, 61, 45, 32.77, 94.57, 6.76, 240.48),\n (9, 29, 34, 29.38, 45.89, 5.73, 100.81),\n (84, 7, 51, 26.82, 87.66, 6.4, 55.74),\n (2, 129, 201, 22.78, 94.37, 5.68, 122.14),\n (110, 21, 54, 26.74, 87.82, 6.75, 47.46),\n (29, 122, 196, 41.95, 81.16, 5.64, 73.07),\n (16, 14, 30, 29.71, 96.3, 6.37, 209.85),\n (33, 14, 8, 21.03, 92.96, 7.68, 110.68),\n (11, 36, 33, 35.99, 52.23, 5.98, 95.37),\n (91, 75, 55, 27.49, 76.11, 6.21, 109.28),\n (42, 59, 55, 40.1, 94.35, 6.98, 149.12),\n (22, 38, 31, 31.53, 53.06, 5.82, 98.57),\n (25, 129, 195, 17.99, 81.18, 5.78, 72.37),\n (34, 38, 31, 35.38, 45.58, 6.45, 97.42),\n (33, 139, 203, 33.34, 82.51, 5.69, 70.68),\n (110, 15, 48, 28.58, 92.87, 6.21, 27.6),\n (112, 87, 48, 27.2, 77.4, 6.2, 99.47),\n (26, 37, 30, 35.4, 49.46, 6.17, 97.41),\n (16, 143, 204, 23.71, 91.53, 5.63, 121.9),\n (24, 14, 33, 29.38, 93.28, 6.37, 218.52),\n (36, 25, 33, 27.98, 53.33, 5.55, 99.61),\n (31, 20, 30, 32.18, 54.01, 6.21, 91.89),\n (70, 68, 45, 33.84, 92.85, 6.99, 203.4),\n (17, 16, 14, 16.4, 92.18, 6.63, 102.94),\n (82, 78, 46, 25.06, 84.97, 5.74, 110.44),\n (22, 18, 31, 30.76, 47.94, 5.96, 90.39),\n (39, 28, 10, 31.35, 91.48, 7.18, 109.15),\n (95, 16, 46, 27.08, 90.14, 6.75, 24.45),\n (4, 19, 43, 18.07, 93.15, 5.78, 106.36),\n (29, 144, 204, 22.43, 92.49, 5.8, 119.1),\n (33, 14, 35, 27.15, 96.66, 6.03, 149.24),\n (4, 20, 25, 28.93, 47.94, 5.66, 99.98),\n (33, 29, 34, 31.41, 49.22, 6.83, 93.0),\n (36, 27, 26, 26.58, 95.79, 6.25, 171.63),\n (19, 26, 29, 26.93, 98.8, 5.67, 166.57),\n (106, 70, 55, 25.87, 78.52, 5.74, 116.3),\n (93, 91, 47, 27.85, 83.31, 6.1, 117.29),\n (39, 127, 202, 15.32, 81.67, 6.48, 71.6),\n (18, 9, 40, 19.45, 89.02, 5.63, 106.16),\n (104, 73, 46, 29.14, 80.12, 6.28, 90.45),\n (15, 123, 204, 22.53, 92.55, 6.37, 115.38),\n (5, 32, 33, 32.32, 52.59, 5.84, 93.37),\n (31, 5, 14, 17.67, 91.7, 6.58, 110.69),\n (22, 9, 44, 24.72, 88.88, 5.74, 112.19),\n (36, 26, 26, 30.17, 51.08, 6.81, 95.23),\n (88, 5, 47, 25.86, 86.67, 6.66, 41.17),\n (35, 18, 26, 31.99, 50.85, 5.28, 97.39),\n (82, 77, 46, 28.95, 82.19, 5.9, 95.83),\n (6, 13, 9, 34.51, 90.56, 7.79, 118.33),\n (82, 77, 46, 28.95, 82.19, 5.9, 95.83),\n (1, 15, 9, 29.98, 94.55, 7.53, 115.36),\n (107, 22, 54, 28.0, 90.85, 6.63, 21.62),\n (110, 28, 46, 24.29, 88.05, 6.5, 51.26),\n (120, 20, 45, 25.67, 88.7, 6.11, 54.23),\n (92, 81, 52, 27.39, 81.47, 6.44, 94.31),\n (39, 7, 29, 27.54, 94.59, 6.36, 150.2),\n (24, 142, 202, 22.54, 91.48, 5.71, 101.85),\n (32, 138, 197, 9.54, 80.73, 5.91, 69.44),\n (100, 14, 49, 29.49, 91.08, 6.37, 26.02),\n (36, 125, 196, 37.47, 80.66, 6.16, 66.84),\n (13, 8, 12, 25.16, 92.55, 7.11, 114.31),\n (22, 28, 26, 27.67, 45.42, 4.95, 92.85),\n (111, 79, 53, 28.31, 75.77, 6.17, 119.7),\n (109, 12, 48, 29.46, 92.13, 6.71, 20.76),\n (18, 23, 8, 21.49, 93.44, 6.41, 101.48),\n (38, 51, 52, 32.66, 90.79, 6.93, 78.85),\n (23, 23, 27, 34.72, 51.43, 5.16, 97.31),\n (2, 36, 31, 30.9, 49.96, 5.73, 91.78),\n (27, 30, 31, 28.99, 90.74, 5.72, 148.84),\n (18, 19, 29, 27.59, 92.49, 6.21, 162.84),\n (38, 51, 52, 32.66, 90.79, 6.93, 68.69),\n (114, 27, 48, 27.82, 93.04, 6.53, 26.32),\n (3, 136, 205, 17.59, 80.85, 6.33, 71.41),\n (82, 25, 51, 24.31, 87.47, 6.07, 48.11),\n (115, 12, 52, 27.51, 94.96, 6.69, 21.02),\n (115, 11, 46, 24.42, 89.4, 6.62, 40.32),\n (12, 20, 10, 24.45, 93.11, 6.53, 109.47),\n (69, 64, 47, 40.21, 94.51, 6.99, 186.68),\n (30, 143, 199, 23.77, 90.6, 5.8, 102.26),\n (105, 14, 50, 26.21, 87.69, 6.42, 59.66),\n (91, 13, 47, 29.11, 92.44, 6.14, 27.96),\n (85, 95, 47, 25.94, 78.34, 6.21, 119.85),\n (101, 13, 54, 25.43, 82.91, 6.83, 56.34),\n (97, 25, 50, 26.22, 80.9, 6.09, 49.09),\n (35, 128, 205, 21.07, 93.57, 6.04, 107.87),\n (104, 25, 55, 29.81, 90.37, 6.12, 22.69),\n (18, 23, 44, 23.71, 89.62, 6.18, 105.65),\n (14, 29, 32, 35.64, 48.97, 6.94, 97.52),\n (40, 5, 32, 26.07, 96.7, 5.98, 143.53),\n (4, 20, 25, 28.93, 47.94, 5.66, 99.98),\n (14, 140, 197, 23.35, 90.9, 6.07, 113.04),\n (33, 12, 8, 25.26, 90.31, 6.82, 117.37),\n (93, 22, 52, 26.59, 81.33, 6.93, 41.88),\n (88, 29, 51, 24.72, 88.95, 6.1, 48.46),\n (37, 126, 196, 23.6, 90.98, 5.6, 107.17),\n (14, 140, 197, 23.35, 90.9, 6.07, 113.04),\n (110, 14, 51, 27.02, 91.67, 6.09, 21.26),\n (37, 23, 12, 31.53, 90.51, 6.4, 113.12),\n (5, 18, 14, 33.11, 93.48, 7.43, 119.17),\n (38, 51, 52, 32.66, 90.79, 6.93, 109.29),\n (37, 24, 13, 19.14, 90.71, 7.85, 108.02),\n (120, 7, 47, 24.25, 83.04, 6.65, 54.77),\n (27, 30, 5, 32.72, 90.55, 7.66, 113.33),\n (4, 134, 200, 28.58, 80.96, 5.84, 73.34),\n (30, 28, 30, 31.87, 52.19, 5.06, 98.47),\n (2, 131, 199, 22.47, 91.23, 6.02, 124.22),\n (69, 64, 47, 40.21, 94.51, 6.99, 186.68),\n (95, 75, 50, 28.08, 75.26, 5.62, 110.71),\n (18, 125, 204, 22.36, 94.48, 6.05, 116.74),\n (12, 20, 10, 24.45, 93.11, 6.53, 109.47),\n (19, 30, 30, 29.57, 91.41, 5.83, 224.83),\n (101, 20, 48, 24.68, 82.75, 6.21, 57.06),\n (18, 5, 11, 20.88, 90.94, 6.25, 102.46),\n (22, 28, 26, 27.67, 45.42, 4.95, 92.85),\n (35, 140, 197, 16.78, 82.75, 6.11, 66.76),\n (83, 10, 53, 24.93, 85.01, 6.2, 48.76),\n (95, 74, 50, 25.9, 80.47, 6.0, 110.1),\n (23, 23, 30, 32.82, 47.46, 4.76, 90.89),\n (1, 8, 26, 27.51, 94.19, 5.56, 156.67),\n (31, 20, 26, 25.57, 97.61, 6.44, 199.79),\n (33, 47, 46, 29.2, 93.97, 6.84, 209.41),\n (102, 28, 54, 25.16, 80.28, 6.86, 55.5),\n (47, 46, 52, 23.19, 91.4, 6.5, 206.4),\n (20, 139, 202, 23.5, 92.21, 5.67, 107.99),\n (102, 73, 52, 27.91, 83.36, 6.36, 90.24),\n (7, 17, 26, 34.89, 48.76, 6.41, 91.63),\n (31, 144, 202, 11.02, 80.56, 5.87, 68.24),\n (8, 28, 30, 25.52, 94.33, 6.02, 135.13),\n (15, 6, 41, 19.01, 88.84, 6.9, 108.68),\n (27, 8, 30, 26.45, 98.3, 6.01, 221.23),\n (2, 40, 27, 29.74, 47.55, 5.95, 90.1),\n (22, 144, 196, 21.91, 91.69, 6.5, 117.08),\n (99, 6, 46, 28.61, 94.22, 6.4, 28.99),\n (6, 123, 203, 12.76, 81.62, 6.13, 66.78),\n (26, 10, 33, 28.27, 96.94, 6.07, 198.82),\n (82, 20, 54, 29.34, 90.02, 6.54, 21.45),\n (34, 38, 31, 35.38, 45.58, 6.45, 97.42),\n (5, 13, 37, 22.34, 89.79, 5.65, 103.32),\n (0, 26, 31, 25.07, 95.02, 5.55, 192.9),\n (19, 17, 39, 24.72, 85.56, 6.73, 111.28),\n (17, 18, 43, 24.49, 90.84, 5.84, 103.2),\n (102, 11, 47, 27.99, 92.78, 6.5, 27.15),\n (21, 21, 30, 27.7, 51.42, 5.4, 100.77),\n (33, 12, 15, 30.26, 92.03, 6.05, 116.72),\n (29, 21, 45, 23.41, 93.13, 6.75, 105.22),\n (16, 6, 29, 29.29, 91.96, 5.87, 132.15),\n (22, 18, 33, 30.41, 52.48, 6.62, 93.92),\n (5, 19, 25, 27.35, 54.44, 6.44, 96.28),\n (101, 75, 50, 26.59, 81.41, 6.24, 109.98),\n (29, 122, 196, 41.95, 81.16, 5.64, 73.07),\n (117, 81, 53, 29.51, 78.21, 5.51, 98.13),\n (3, 27, 44, 24.57, 92.03, 6.59, 110.96),\n (110, 25, 54, 28.91, 90.78, 6.43, 23.44),\n (25, 129, 195, 17.99, 81.18, 5.78, 72.37),\n (10, 136, 204, 21.2, 92.16, 6.28, 105.86),\n (38, 15, 27, 33.75, 48.5, 6.78, 92.26),\n (15, 125, 199, 18.43, 80.56, 5.57, 69.76),\n (50, 59, 47, 40.77, 92.09, 6.75, 209.87),\n (17, 18, 43, 24.49, 90.84, 5.84, 103.2),\n (38, 21, 35, 20.34, 89.38, 5.84, 110.97),\n (37, 6, 13, 26.03, 91.51, 7.51, 101.28),\n (110, 28, 46, 24.29, 88.05, 6.5, 51.26),\n (92, 81, 52, 27.39, 81.47, 6.44, 94.31),\n (13, 5, 8, 23.85, 90.11, 7.47, 103.92),\n (44, 64, 54, 29.81, 91.38, 6.74, 232.7),\n (5, 13, 37, 22.34, 89.79, 5.65, 103.32),\n (104, 17, 46, 25.71, 80.23, 6.19, 43.09),\n (18, 21, 35, 23.28, 94.94, 6.37, 111.14),\n (0, 19, 31, 25.52, 94.38, 6.27, 178.73),\n (30, 17, 31, 31.2, 54.5, 6.8, 94.63),\n (86, 95, 49, 28.05, 78.05, 6.46, 108.4),\n (39, 17, 45, 18.1, 90.42, 6.92, 104.88),\n (61, 68, 50, 35.21, 91.5, 6.79, 243.07),\n (36, 26, 26, 30.17, 51.08, 6.81, 95.23),\n (40, 11, 44, 24.46, 86.11, 6.32, 111.38),\n (34, 65, 48, 41.42, 90.04, 6.67, 199.31),\n (11, 132, 197, 15.99, 81.24, 5.73, 74.4),\n (10, 140, 197, 22.17, 90.27, 6.23, 124.47),\n (102, 71, 48, 28.65, 79.29, 5.7, 102.46),\n (15, 9, 11, 11.55, 94.15, 7.91, 108.83),\n (120, 87, 52, 28.08, 76.06, 5.91, 118.99),\n (13, 16, 8, 34.74, 93.12, 6.95, 100.2),\n (27, 30, 5, 32.72, 90.55, 7.66, 113.33),\n (100, 18, 52, 26.2, 80.38, 6.88, 56.48),\n (107, 12, 46, 29.57, 93.62, 6.56, 27.57),\n (12, 20, 39, 19.86, 86.2, 6.03, 116.08),\n (27, 138, 201, 23.67, 93.9, 5.95, 105.4),\n (6, 9, 12, 31.08, 90.14, 7.03, 109.69),\n (4, 20, 25, 28.93, 47.94, 5.66, 99.98),\n (31, 20, 26, 25.57, 97.61, 6.44, 199.79),\n (39, 65, 53, 35.33, 92.12, 6.56, 235.61),\n (14, 5, 36, 24.93, 85.19, 5.83, 104.77),\n (102, 25, 50, 28.2, 92.91, 6.1, 20.36),\n (6, 13, 29, 27.31, 99.97, 5.83, 201.83),\n (0, 25, 14, 19.34, 91.98, 6.36, 116.45),\n (0, 19, 31, 25.52, 94.38, 6.27, 71.74),\n (25, 12, 26, 28.57, 95.68, 6.44, 134.84),\n (40, 22, 6, 24.54, 91.91, 6.49, 115.98),\n (8, 15, 33, 28.97, 98.1, 5.5, 213.9),\n (97, 22, 50, 26.26, 86.15, 6.77, 58.98),\n (36, 7, 37, 19.87, 86.36, 5.78, 73.01),\n (111, 15, 54, 27.71, 92.91, 6.19, 22.06),\n (40, 65, 49, 35.33, 91.06, 6.68, 163.91),\n (33, 121, 203, 22.46, 94.76, 5.61, 114.84),\n (52, 51, 53, 38.38, 93.1, 6.99, 210.27),\n (0, 17, 30, 35.47, 47.97, 6.28, 97.79),\n (31, 20, 30, 32.18, 54.01, 6.21, 91.89),\n (9, 16, 39, 18.41, 91.12, 6.1, 105.18),\n (112, 73, 48, 29.24, 77.32, 5.71, 90.67),\n (37, 24, 13, 19.14, 90.71, 7.85, 108.02),\n (32, 141, 203, 21.26, 92.84, 5.82, 109.07),\n (12, 20, 39, 19.86, 86.2, 6.03, 116.08),\n (23, 5, 44, 21.21, 94.26, 7.16, 107.57),\n (1, 17, 6, 10.79, 91.38, 6.82, 117.53),\n (8, 133, 195, 20.47, 80.98, 6.46, 71.3),\n (108, 94, 47, 27.36, 84.55, 6.39, 90.81),\n (2, 123, 205, 22.37, 90.79, 5.74, 124.98),\n (21, 9, 40, 24.51, 90.64, 5.96, 105.62),\n (69, 64, 47, 40.21, 94.51, 6.99, 186.68),\n (25, 7, 35, 28.39, 99.19, 5.56, 189.67),\n (95, 16, 55, 25.27, 87.55, 6.61, 40.13),\n (37, 124, 195, 18.71, 83.48, 6.21, 66.6),\n (30, 122, 197, 21.38, 92.72, 5.57, 113.25),\n (69, 66, 49, 40.0, 90.17, 6.53, 92.12),\n (7, 28, 35, 30.02, 46.78, 4.67, 96.64),\n (19, 7, 10, 14.78, 91.22, 6.12, 100.2),\n (17, 136, 195, 41.21, 81.61, 6.39, 65.9),\n (37, 36, 27, 27.55, 47.91, 5.91, 90.4),\n (101, 17, 47, 29.49, 94.73, 6.19, 26.31),\n (37, 137, 199, 22.64, 90.18, 5.7, 108.34),\n (24, 21, 42, 20.82, 87.23, 7.0, 109.44),\n (35, 142, 203, 21.17, 90.24, 5.9, 123.65),\n (37, 23, 12, 31.53, 90.51, 6.4, 113.12),\n (37, 36, 27, 27.55, 47.91, 5.91, 90.4),\n (4, 19, 43, 18.07, 93.15, 5.78, 106.36),\n (2, 21, 35, 25.03, 91.54, 6.29, 179.82),\n (20, 28, 26, 26.38, 91.5, 5.55, 167.05),\n (6, 30, 40, 22.77, 91.45, 6.36, 116.55),\n (26, 37, 30, 35.4, 49.46, 6.17, 97.41),\n (59, 47, 53, 32.86, 91.46, 6.85, 47.27),\n (90, 16, 45, 24.92, 80.62, 6.29, 50.56),\n (18, 12, 8, 12.59, 91.82, 6.21, 119.39),\n (37, 36, 26, 32.89, 52.61, 4.65, 94.49),\n (18, 125, 203, 22.44, 91.59, 6.16, 102.56),\n (98, 7, 45, 27.79, 92.51, 6.16, 26.85),\n (61, 51, 51, 39.3, 94.16, 6.57, 120.95),\n (38, 51, 52, 32.66, 90.79, 6.93, 94.38),\n (22, 23, 44, 20.13, 89.32, 6.14, 107.34),\n (89, 22, 52, 24.9, 86.11, 6.22, 53.15),\n (26, 18, 42, 19.73, 89.65, 6.91, 108.23),\n (100, 80, 52, 27.54, 77.26, 6.05, 110.33),\n (35, 142, 203, 21.17, 90.24, 5.9, 123.65),\n (81, 18, 50, 26.44, 80.92, 6.51, 47.82),\n (104, 80, 54, 27.09, 81.34, 5.88, 110.13),\n (2, 21, 44, 18.92, 87.31, 6.57, 102.8),\n (38, 15, 27, 33.75, 48.5, 6.78, 92.26),\n (5, 144, 205, 21.42, 92.63, 6.18, 102.8),\n (14, 128, 205, 22.61, 94.59, 6.23, 116.04),\n (6, 139, 199, 25.67, 81.62, 6.29, 74.11),\n (40, 17, 15, 21.35, 90.95, 7.87, 107.09),\n (49, 55, 51, 24.87, 93.91, 6.68, 135.17),\n (32, 129, 201, 16.36, 83.0, 6.49, 71.56),\n (28, 123, 198, 23.46, 91.46, 5.68, 111.78),\n (31, 68, 45, 42.92, 90.08, 6.94, 196.24),\n (7, 21, 35, 25.76, 94.66, 5.76, 131.25),\n (83, 22, 54, 25.9, 81.97, 6.28, 54.5),\n (25, 132, 198, 22.32, 90.85, 5.73, 100.12),\n (34, 21, 42, 18.76, 89.93, 6.65, 111.02),\n (31, 5, 14, 17.67, 91.7, 6.58, 110.69),\n (34, 68, 51, 27.35, 94.18, 6.69, 40.35),\n (104, 80, 54, 27.09, 81.34, 5.88, 110.13),\n (15, 133, 199, 24.0, 91.61, 5.82, 117.61),\n (32, 121, 199, 39.37, 81.25, 6.13, 74.08),\n (107, 22, 54, 28.0, 90.85, 6.63, 21.62),\n (99, 6, 45, 26.13, 86.55, 6.0, 40.71),\n (36, 11, 13, 17.34, 93.05, 7.19, 112.72),\n (83, 15, 49, 28.93, 91.39, 6.44, 23.2),\n (120, 19, 49, 25.79, 84.27, 6.76, 56.45),\n (95, 75, 45, 28.98, 82.96, 5.83, 109.02),\n (19, 120, 195, 18.74, 81.12, 5.93, 73.56),\n (87, 21, 52, 27.35, 94.29, 6.07, 27.21),\n (6, 30, 40, 22.77, 91.45, 6.36, 116.55),\n (4, 6, 7, 23.01, 91.12, 6.71, 112.67),\n (39, 129, 203, 34.39, 83.18, 5.86, 71.03),\n (28, 6, 40, 22.11, 91.34, 6.77, 106.87),\n (36, 59, 46, 34.29, 93.61, 6.72, 127.25),\n (14, 131, 198, 33.46, 83.87, 5.56, 67.92),\n (0, 145, 205, 21.23, 90.1, 5.52, 113.98),\n (3, 27, 44, 24.57, 92.03, 6.59, 110.96),\n (100, 76, 45, 25.57, 75.94, 5.59, 102.79),\n (8, 26, 36, 18.78, 87.4, 6.8, 102.52),\n (110, 14, 51, 27.02, 91.67, 6.09, 21.26),\n (4, 40, 26, 27.58, 48.57, 6.72, 95.84),\n (95, 75, 50, 28.08, 75.26, 5.62, 118.28),\n (56, 57, 48, 31.56, 93.05, 6.51, 63.62),\n (86, 15, 47, 24.04, 84.18, 6.42, 53.79),\n (23, 7, 34, 26.11, 91.52, 5.85, 134.13),\n (21, 31, 32, 35.39, 51.43, 5.25, 90.3),\n (65, 62, 51, 31.53, 90.87, 6.51, 207.07),\n (5, 19, 25, 27.35, 54.44, 6.44, 96.28),\n (18, 20, 26, 31.67, 51.99, 5.44, 89.98),\n (95, 26, 45, 29.92, 94.56, 6.12, 28.16),\n (104, 25, 51, 28.96, 93.88, 6.47, 23.56),\n (38, 6, 25, 25.55, 96.93, 6.16, 191.3),\n (9, 21, 32, 32.27, 53.56, 5.87, 95.94),\n (0, 137, 195, 22.44, 80.19, 6.33, 65.4),\n (40, 16, 35, 31.89, 49.02, 6.48, 89.59),\n (84, 25, 52, 24.37, 81.25, 6.13, 44.21),\n (23, 142, 197, 39.07, 82.04, 6.0, 69.31),\n (94, 5, 55, 28.59, 91.89, 6.09, 26.88),\n (0, 17, 30, 35.47, 47.97, 6.28, 97.79),\n (40, 132, 202, 24.58, 80.71, 5.97, 69.71),\n (22, 23, 44, 20.13, 89.32, 6.14, 107.34),\n (39, 28, 10, 31.35, 91.48, 7.18, 109.15),\n (38, 6, 25, 25.55, 96.93, 6.16, 191.3),\n (44, 60, 55, 34.28, 90.56, 6.83, 98.54),\n (39, 25, 36, 18.9, 95.0, 5.57, 107.61),\n (60, 58, 51, 42.07, 92.92, 6.84, 165.74),\n (13, 28, 33, 28.13, 95.65, 5.69, 151.08),\n (0, 26, 31, 25.07, 95.02, 5.55, 192.9),\n (20, 139, 202, 23.5, 92.21, 5.67, 107.99),\n (120, 8, 46, 29.56, 90.71, 6.73, 28.37),\n (16, 15, 42, 19.68, 89.09, 6.89, 108.55),\n (68, 52, 49, 24.43, 92.28, 6.58, 63.35),\n (80, 90, 47, 26.6, 79.36, 6.21, 107.39),\n (11, 36, 31, 27.92, 51.78, 6.48, 100.26),\n (14, 23, 25, 26.19, 96.97, 5.61, 135.42),\n (8, 133, 195, 20.47, 80.98, 6.46, 71.3),\n (93, 22, 52, 26.59, 81.33, 6.93, 41.88),\n (1, 8, 26, 27.51, 94.19, 5.56, 156.67),\n (6, 30, 40, 22.77, 91.45, 6.36, 106.97),\n (100, 6, 53, 29.05, 93.92, 6.11, 23.67),\n (61, 51, 51, 39.3, 94.16, 6.57, 120.95),\n (95, 16, 46, 27.08, 90.14, 6.75, 24.45),\n (117, 86, 48, 28.7, 82.54, 6.23, 116.16),\n (12, 34, 28, 33.36, 45.02, 6.14, 98.82),\n (13, 144, 197, 22.92, 94.9, 6.28, 105.69),\n (31, 8, 7, 34.51, 93.64, 7.16, 103.57),\n (1, 30, 29, 28.33, 51.4, 6.43, 91.67),\n (10, 125, 196, 22.31, 90.04, 5.73, 113.07),\n (109, 91, 53, 29.67, 83.51, 6.01, 110.25),\n (30, 122, 197, 21.38, 92.72, 5.57, 106.14),\n (34, 15, 34, 27.06, 91.11, 5.68, 224.7),\n (36, 125, 196, 37.47, 80.66, 6.16, 66.84),\n (27, 24, 41, 24.33, 90.88, 6.61, 110.46),\n (95, 13, 46, 29.84, 93.76, 6.13, 23.28),\n (14, 25, 40, 20.07, 90.98, 6.41, 103.71),\n (22, 30, 12, 15.78, 92.51, 6.35, 119.04),\n (118, 12, 47, 27.97, 92.17, 6.01, 28.95),\n (110, 7, 45, 26.64, 84.7, 6.19, 48.32),\n (14, 131, 198, 33.46, 83.87, 5.56, 67.92),\n (26, 122, 202, 22.45, 94.74, 5.62, 107.18),\n (7, 11, 32, 29.26, 95.11, 5.54, 184.76),\n (20, 7, 9, 29.48, 91.58, 7.13, 111.17),\n (98, 26, 52, 27.34, 90.7, 6.15, 28.69),\n (26, 11, 11, 13.7, 90.96, 7.61, 106.29),\n (108, 88, 55, 26.29, 83.39, 5.89, 113.87),\n (36, 19, 32, 27.11, 50.71, 4.94, 92.37),\n (8, 7, 10, 28.26, 91.98, 6.93, 105.21),\n (39, 24, 31, 33.56, 53.73, 4.76, 98.68),\n (67, 68, 49, 35.27, 92.38, 6.82, 149.85),\n (114, 8, 50, 24.75, 88.31, 6.58, 57.96),\n (90, 92, 55, 27.01, 80.19, 6.13, 97.33),\n (93, 22, 48, 29.13, 91.52, 6.78, 21.9),\n (36, 25, 33, 27.98, 53.33, 5.55, 99.61),\n (38, 6, 25, 25.55, 96.93, 6.16, 191.3),\n (38, 61, 52, 31.23, 94.94, 6.62, 46.44),\n (18, 19, 29, 27.59, 92.49, 6.21, 162.84),\n (106, 10, 49, 27.73, 92.01, 6.35, 20.21),\n (101, 75, 50, 26.59, 81.41, 6.24, 109.98),\n (35, 67, 49, 41.31, 91.15, 6.62, 239.74),\n (29, 17, 29, 29.2, 95.67, 5.96, 211.25),\n (11, 143, 197, 22.98, 93.32, 5.88, 122.2),\n (2, 123, 205, 22.37, 90.79, 5.74, 124.98),\n (0, 12, 7, 20.18, 90.65, 6.97, 116.81),\n (40, 22, 6, 24.54, 91.91, 6.49, 115.98),\n (48, 57, 54, 29.02, 90.2, 6.62, 126.81),\n (39, 24, 39, 23.65, 93.33, 6.43, 109.81),\n (22, 26, 38, 22.92, 85.13, 6.99, 110.24),\n (6, 30, 40, 22.77, 91.45, 6.36, 116.55),\n (40, 17, 15, 21.35, 90.95, 7.87, 107.09),\n (56, 58, 49, 37.13, 94.61, 6.69, 172.48),\n (9, 16, 36, 23.78, 92.93, 5.89, 106.98),\n (8, 28, 38, 23.23, 94.43, 6.84, 105.69),\n (107, 71, 55, 29.42, 83.97, 6.09, 117.23),\n (39, 30, 38, 20.13, 87.6, 6.97, 108.07),\n (34, 38, 31, 35.38, 45.58, 6.45, 97.42),\n (8, 26, 36, 18.78, 87.4, 6.8, 102.52),\n (98, 25, 52, 25.28, 83.15, 6.22, 49.29),\n (119, 90, 48, 28.67, 79.59, 5.99, 118.26),\n (6, 7, 7, 27.68, 94.47, 7.2, 114.0),\n (95, 88, 52, 28.0, 78.9, 6.24, 94.68),\n (30, 122, 197, 21.38, 92.72, 5.57, 106.14),\n (37, 137, 199, 22.64, 90.18, 5.7, 108.34),\n (32, 55, 52, 37.59, 92.0, 6.97, 159.66),\n (14, 18, 30, 29.81, 52.14, 5.19, 95.75),\n (15, 27, 28, 33.8, 46.13, 4.51, 90.83),\n (30, 13, 25, 27.15, 91.49, 6.41, 164.92),\n (28, 122, 197, 19.89, 82.73, 5.86, 69.66),\n (93, 85, 49, 27.97, 79.29, 5.69, 119.48),\n (111, 79, 53, 28.31, 75.77, 6.17, 119.7),\n (23, 138, 195, 22.49, 91.7, 5.8, 124.39),\n (22, 133, 201, 23.82, 80.12, 6.0, 67.27),\n (0, 5, 36, 24.35, 90.89, 6.15, 105.53),\n (38, 61, 52, 31.23, 94.94, 6.62, 46.44),\n (32, 25, 35, 18.1, 85.71, 5.89, 107.01),\n (25, 21, 11, 32.24, 90.15, 6.46, 104.71),\n (34, 6, 30, 27.08, 97.0, 5.95, 171.76),\n (0, 17, 30, 35.47, 47.97, 6.28, 97.79),\n (9, 141, 202, 21.01, 81.18, 6.12, 66.38),\n (82, 20, 54, 29.34, 90.02, 6.54, 21.45),\n (91, 7, 52, 25.08, 83.46, 6.41, 56.4),\n (91, 75, 55, 27.49, 76.11, 6.21, 109.28),\n (39, 24, 14, 30.55, 90.9, 7.19, 106.07),\n (32, 25, 35, 18.1, 85.71, 5.89, 107.01),\n (39, 145, 201, 36.73, 80.59, 5.78, 72.24),\n (113, 6, 52, 27.76, 90.36, 6.74, 25.22),\n (99, 92, 47, 28.13, 77.48, 6.32, 103.5),\n (84, 7, 51, 26.82, 87.66, 6.4, 55.74),\n (85, 25, 47, 26.11, 87.64, 6.3, 58.48),\n (0, 26, 31, 25.07, 95.02, 5.55, 192.9),\n (26, 15, 6, 17.22, 94.79, 6.91, 108.01),\n (37, 11, 36, 24.25, 85.56, 6.71, 106.92),\n (95, 23, 45, 27.82, 90.57, 6.27, 21.19),\n (16, 6, 29, 29.29, 91.96, 5.87, 132.15),\n (4, 134, 200, 28.58, 80.96, 5.84, 73.34),\n (112, 73, 48, 29.24, 77.32, 5.71, 90.67),\n (9, 16, 36, 23.78, 92.93, 5.89, 106.98),\n (20, 122, 204, 11.8, 80.86, 6.49, 65.07),\n (9, 8, 40, 22.49, 89.92, 6.55, 111.66),\n (40, 18, 43, 19.39, 86.79, 5.77, 109.91),\n (115, 11, 46, 24.42, 89.4, 6.62, 40.32),\n (5, 15, 38, 18.26, 88.17, 5.71, 108.08),\n (113, 19, 46, 25.42, 81.12, 6.29, 49.52),\n (23, 7, 34, 26.11, 91.52, 5.85, 134.13),\n (5, 24, 40, 24.69, 93.87, 6.3, 104.67),\n (34, 16, 25, 30.07, 50.96, 6.11, 92.1),\n (84, 25, 52, 24.37, 81.25, 6.13, 44.21),\n (113, 20, 48, 27.47, 94.88, 6.44, 27.28),\n (29, 21, 45, 23.41, 93.13, 6.75, 105.22),\n (16, 145, 199, 26.92, 80.77, 5.95, 69.31),\n (37, 52, 47, 43.08, 93.9, 6.54, 211.85),\n (114, 21, 55, 25.44, 87.94, 6.47, 57.52),\n (53, 55, 55, 33.32, 91.25, 6.71, 234.5),\n (119, 25, 51, 26.47, 80.92, 6.28, 53.66),\n (1, 35, 34, 30.79, 46.7, 6.27, 92.21),\n (7, 144, 197, 23.85, 94.35, 6.13, 114.05),\n (1, 124, 199, 23.71, 93.27, 5.66, 115.57),\n (21, 20, 31, 25.6, 99.72, 5.86, 165.82),\n (20, 20, 10, 11.87, 93.68, 6.98, 106.06),\n (22, 16, 27, 29.18, 90.27, 6.01, 188.93),\n (117, 30, 50, 24.9, 87.21, 6.74, 46.59),\n (28, 145, 202, 19.21, 82.9, 6.48, 66.83),\n (30, 30, 35, 25.01, 95.59, 6.0, 165.81),\n (97, 25, 50, 26.22, 80.9, 6.09, 49.09),\n (21, 135, 198, 23.86, 94.92, 5.77, 105.02),\n (103, 16, 49, 24.07, 81.64, 6.92, 51.75),\n (2, 120, 203, 23.13, 94.71, 5.89, 108.62),\n (50, 60, 47, 32.58, 92.75, 6.93, 93.79),\n (38, 21, 35, 20.34, 89.38, 5.84, 110.97),\n (27, 145, 205, 9.47, 82.29, 5.8, 66.03),\n (100, 17, 48, 29.73, 94.3, 6.37, 26.52),\n (109, 10, 53, 26.82, 87.83, 6.55, 46.06),\n (32, 138, 197, 9.54, 80.73, 5.91, 69.44),\n (59, 62, 49, 43.36, 93.35, 6.94, 114.78),\n (32, 55, 52, 37.59, 92.0, 6.97, 159.66),\n (16, 29, 13, 32.32, 93.68, 6.2, 117.62),\n (29, 138, 197, 22.19, 92.44, 5.83, 121.66),\n (34, 62, 55, 27.59, 90.73, 6.59, 238.5),\n (25, 12, 26, 28.57, 95.68, 6.44, 134.84),\n (83, 7, 45, 29.08, 90.74, 6.7, 25.33),\n (2, 21, 44, 18.92, 87.31, 6.57, 102.8),\n (114, 30, 51, 29.25, 90.07, 6.07, 25.93),\n (27, 13, 6, 13.36, 91.36, 7.34, 111.23),\n (13, 144, 204, 30.73, 82.43, 6.09, 68.38),\n (107, 72, 45, 28.15, 81.54, 5.79, 91.41),\n (120, 7, 47, 24.25, 83.04, 6.65, 54.77),\n (6, 144, 198, 21.11, 90.32, 5.56, 104.51),\n (34, 15, 34, 27.06, 91.11, 5.68, 224.7),\n (108, 23, 51, 26.84, 83.85, 6.11, 40.23),\n (1, 124, 199, 23.71, 93.27, 5.66, 112.67),\n (95, 7, 45, 27.3, 90.8, 6.03, 25.09),\n (31, 29, 26, 28.22, 47.41, 5.02, 97.77),\n (31, 25, 12, 18.05, 90.04, 7.02, 111.78),\n (34, 65, 48, 41.42, 90.04, 6.67, 199.31),\n (20, 20, 10, 11.87, 93.68, 6.98, 106.06),\n (32, 130, 196, 40.66, 81.25, 6.37, 74.03),\n (83, 94, 47, 27.4, 81.11, 6.47, 112.14),\n (11, 132, 197, 15.99, 81.24, 5.73, 74.4),\n (35, 128, 205, 21.07, 93.57, 6.04, 107.87),\n (22, 18, 31, 30.76, 47.94, 5.96, 90.39),\n (60, 46, 53, 24.49, 92.98, 6.76, 183.49),\n (7, 17, 10, 10.16, 91.22, 6.47, 106.36),\n (28, 130, 196, 22.13, 94.68, 6.06, 112.92),\n (21, 21, 30, 27.7, 51.42, 5.4, 100.77),\n (30, 28, 30, 31.87, 52.19, 5.06, 98.47),\n (16, 15, 42, 19.68, 89.09, 6.89, 108.55),\n (29, 25, 14, 30.49, 90.46, 7.78, 113.33),\n (83, 22, 54, 25.9, 81.97, 6.28, 54.5),\n (104, 17, 46, 25.71, 80.23, 6.19, 43.09),\n (22, 17, 5, 24.12, 90.72, 6.95, 102.84),\n (39, 30, 38, 20.13, 87.6, 6.97, 108.07),\n (50, 60, 47, 32.58, 92.75, 6.93, 93.79),\n (117, 86, 53, 25.2, 83.56, 5.7, 115.86),\n (16, 10, 41, 24.77, 85.64, 6.74, 105.76),\n (6, 124, 200, 22.98, 93.85, 5.97, 109.59),\n (40, 22, 29, 27.56, 99.98, 5.74, 174.63),\n (29, 22, 40, 23.63, 89.73, 6.15, 107.68),\n (32, 11, 31, 29.52, 92.56, 6.46, 131.21),\n (83, 15, 49, 28.93, 91.39, 6.44, 23.2),\n (82, 23, 49, 26.81, 87.22, 6.87, 51.7),\n (37, 10, 32, 28.96, 95.16, 6.17, 222.8),\n (11, 18, 42, 21.58, 94.88, 5.94, 90.22),\n (82, 75, 55, 27.35, 78.49, 6.28, 92.16),\n (91, 21, 50, 24.34, 81.44, 6.76, 48.32),\n (21, 139, 201, 19.36, 83.36, 5.98, 67.15),\n (29, 139, 205, 23.64, 93.74, 6.16, 116.69),\n (54, 67, 52, 35.68, 93.31, 6.59, 141.34),\n (34, 48, 48, 41.04, 91.37, 6.81, 181.53),\n (80, 77, 49, 26.05, 79.4, 5.52, 113.23),\n (5, 16, 31, 35.96, 48.7, 4.56, 98.01),\n ...]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T09:49:40.339687800Z",
     "start_time": "2024-03-20T09:49:40.294191Z"
    }
   },
   "id": "19bf0eee42b1464c",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mitbo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": "array(['apple', 'banana', 'coconut', 'grapes', 'mango', 'muskmelon',\n       'orange', 'papaya', 'pomegranate', 'watermelon'], dtype='<U11')"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Convert Ytrain into Numbers from categoories\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "le.fit(Ytrain)\n",
    "\n",
    "le.classes_"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T09:49:41.834799200Z",
     "start_time": "2024-03-20T09:49:41.812391200Z"
    }
   },
   "id": "cf01642835a7f683",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mitbo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "C:\\Users\\mitbo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    }
   ],
   "source": [
    "Ytrain = le.transform(Ytrain)\n",
    "Ytest = le.transform(Ytest)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T09:49:46.814876200Z",
     "start_time": "2024-03-20T09:49:46.806050600Z"
    }
   },
   "id": "8ac9c92330ee677b",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([3, 1, 9, ..., 0, 5, 5])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytrain"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T09:49:48.695670500Z",
     "start_time": "2024-03-20T09:49:48.679874600Z"
    }
   },
   "id": "63beb0fb53bc4dfa",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler to the train set,it will learn the parameters\n",
    "scaler.fit(Xtrain)\n",
    "\n",
    "# Transform train and test sets\n",
    "Xtrain_scaled =  scaler.transform(Xtrain)\n",
    "Xtest_scaled =  scaler.transform(Xtest)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T09:49:50.178540500Z",
     "start_time": "2024-03-20T09:49:50.148104400Z"
    }
   },
   "id": "7b650fbc0d5742bf",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T09:49:52.061089Z",
     "start_time": "2024-03-20T09:49:52.054980900Z"
    }
   },
   "id": "131ebec5d4c03a04",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.26666667, 0.82857143, 0.97      , ..., 0.6592067 , 0.46418338,\n        0.23560026],\n       [0.76666667, 0.57142857, 0.23      , ..., 0.65611354, 0.35243553,\n        0.38771047],\n       [0.675     , 0.09285714, 0.225     , ..., 0.65320233, 0.5730659 ,\n        0.12075224],\n       ...,\n       [0.18333333, 0.99285714, 0.955     , ..., 0.84916303, 0.57020057,\n        0.42366062],\n       [1.        , 0.12857143, 0.25      , ..., 0.84770742, 0.63610315,\n        0.02742182],\n       [0.89166667, 0.12142857, 0.245     , ..., 0.83387918, 0.60744986,\n        0.00616663]])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain_scaled"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T09:49:52.746561100Z",
     "start_time": "2024-03-20T09:49:52.718855700Z"
    }
   },
   "id": "aa9a39cad8ba17ac",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m Xtrain_scaled \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(Xtrain_scaled, columns\u001B[38;5;241m=\u001B[39m\u001B[43mXtrain\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m)\n\u001B[0;32m      2\u001B[0m Xtest_scaled \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(Xtest_scaled,columns\u001B[38;5;241m=\u001B[39mXtest\u001B[38;5;241m.\u001B[39mcolumns)\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'list' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "Xtrain_scaled = pd.DataFrame(Xtrain_scaled, columns=Xtrain.columns)\n",
    "Xtest_scaled = pd.DataFrame(Xtest_scaled,columns=Xtest.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T09:49:57.024625500Z",
     "start_time": "2024-03-20T09:49:56.523068800Z"
    }
   },
   "id": "7df71fa45147d04",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "## Here,I'm initializing empty lists to append all model's name and corresponding name\n",
    "acc = []\n",
    "model = []"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T06:24:54.856510300Z",
     "start_time": "2024-03-20T06:24:54.844980900Z"
    }
   },
   "id": "4b501312010e9329",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree's Accuracy is:  95.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95        21\n",
      "           1       0.95      0.86      0.90        21\n",
      "           2       1.00      1.00      1.00        17\n",
      "           3       0.89      1.00      0.94        17\n",
      "           4       0.92      0.96      0.94        24\n",
      "           5       1.00      1.00      1.00        21\n",
      "           6       1.00      0.87      0.93        15\n",
      "           7       0.96      0.93      0.95        28\n",
      "           8       0.88      1.00      0.94        15\n",
      "           9       1.00      1.00      1.00        21\n",
      "\n",
      "    accuracy                           0.95       200\n",
      "   macro avg       0.96      0.96      0.95       200\n",
      "weighted avg       0.96      0.95      0.95       200\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "\n",
    "DecisionTree = DecisionTreeClassifier(criterion = \"entropy\",random_state=2,max_depth=5)\n",
    "\n",
    "DecisionTree.fit(Xtrain_scaled,Ytrain)\n",
    "\n",
    "predicted_values = DecisionTree.predict(Xtest_scaled)\n",
    "x = metrics.accuracy_score(Ytest,predicted_values)\n",
    "acc.append(x*100)\n",
    "model.append('Decision Tree')\n",
    "print(\"Decision Tree's Accuracy is: \",x*100)\n",
    "\n",
    "print(classification_report(Ytest,predicted_values))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T06:24:56.538734300Z",
     "start_time": "2024-03-20T06:24:56.063909900Z"
    }
   },
   "id": "2bb16d5174c01d9e",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes's Accuracy is:  98.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        21\n",
      "           1       0.95      0.86      0.90        21\n",
      "           2       1.00      1.00      1.00        17\n",
      "           3       1.00      1.00      1.00        17\n",
      "           4       1.00      1.00      1.00        24\n",
      "           5       1.00      1.00      1.00        21\n",
      "           6       1.00      1.00      1.00        15\n",
      "           7       0.97      1.00      0.98        28\n",
      "           8       0.88      1.00      0.94        15\n",
      "           9       1.00      1.00      1.00        21\n",
      "\n",
      "    accuracy                           0.98       200\n",
      "   macro avg       0.98      0.98      0.98       200\n",
      "weighted avg       0.98      0.98      0.98       200\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "NaiveBayes = GaussianNB()\n",
    "\n",
    "NaiveBayes.fit(Xtrain_scaled,Ytrain)\n",
    "\n",
    "predicted_values = NaiveBayes.predict(Xtest_scaled)\n",
    "\n",
    "x =metrics.accuracy_score(Ytest, predicted_values)\n",
    "acc.append(x*100)\n",
    "model.append('Naive Bayes')\n",
    "\n",
    "print(\"Naive Bayes's Accuracy is: \", x*100)\n",
    "\n",
    "print(classification_report(Ytest,predicted_values))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T06:25:04.690912Z",
     "start_time": "2024-03-20T06:25:04.677852200Z"
    }
   },
   "id": "78c92f7d102a62a9",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM's Accuracy is:  22.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.14      0.25        21\n",
      "           1       0.00      0.00      0.00        21\n",
      "           2       1.00      0.18      0.30        17\n",
      "           3       1.00      0.12      0.21        17\n",
      "           4       1.00      0.08      0.15        24\n",
      "           5       1.00      0.48      0.65        21\n",
      "           6       0.09      1.00      0.16        15\n",
      "           7       0.00      0.00      0.00        28\n",
      "           8       1.00      0.67      0.80        15\n",
      "           9       0.00      0.00      0.00        21\n",
      "\n",
      "    accuracy                           0.23       200\n",
      "   macro avg       0.61      0.27      0.25       200\n",
      "weighted avg       0.58      0.23      0.23       200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mitbo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\mitbo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\mitbo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC \n",
    "\n",
    "SVM = SVC(gamma='auto')\n",
    "\n",
    "SVM.fit(Xtrain, Ytrain)\n",
    "\n",
    "predicted_values = SVM.predict(Xtest)\n",
    "\n",
    "x = metrics.accuracy_score(Ytest,predicted_values)\n",
    "acc.append(x*100)\n",
    "model.append('SVM')\n",
    "print(\"SVM's Accuracy is: \", x*100)\n",
    "\n",
    "print(classification_report(Ytest,predicted_values))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T06:25:13.588948300Z",
     "start_time": "2024-03-20T06:25:13.517786400Z"
    }
   },
   "id": "8817830265eb4664",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistics Regression's Accuracy is:  96.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        21\n",
      "           1       0.95      0.86      0.90        21\n",
      "           2       1.00      0.94      0.97        17\n",
      "           3       0.94      1.00      0.97        17\n",
      "           4       1.00      1.00      1.00        24\n",
      "           5       1.00      1.00      1.00        21\n",
      "           6       0.94      1.00      0.97        15\n",
      "           7       0.96      0.89      0.93        28\n",
      "           8       0.79      1.00      0.88        15\n",
      "           9       1.00      1.00      1.00        21\n",
      "\n",
      "    accuracy                           0.96       200\n",
      "   macro avg       0.96      0.96      0.96       200\n",
      "weighted avg       0.96      0.96      0.96       200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mitbo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LogReg = LogisticRegression(random_state=2)\n",
    "\n",
    "LogReg.fit(Xtrain,Ytrain)\n",
    "\n",
    "predicted_values = LogReg.predict(Xtest)\n",
    "\n",
    "x = metrics.accuracy_score(Ytest, predicted_values)\n",
    "\n",
    "acc.append(x*100)\n",
    "model.append('Logistic Regression')\n",
    "print(\"Logistics Regression's Accuracy is: \",x*100)\n",
    "\n",
    "print(classification_report(Ytest,predicted_values))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T06:25:22.554892400Z",
     "start_time": "2024-03-20T06:25:22.507686700Z"
    }
   },
   "id": "cd7e1e5864bd4b1c",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression on Scaled data Accuracy is:  95.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        21\n",
      "           1       0.95      0.86      0.90        21\n",
      "           2       1.00      1.00      1.00        17\n",
      "           3       1.00      1.00      1.00        17\n",
      "           4       1.00      1.00      1.00        24\n",
      "           5       0.95      1.00      0.98        21\n",
      "           6       0.74      0.93      0.82        15\n",
      "           7       0.96      0.93      0.95        28\n",
      "           8       0.86      0.80      0.83        15\n",
      "           9       1.00      1.00      1.00        21\n",
      "\n",
      "    accuracy                           0.95       200\n",
      "   macro avg       0.95      0.95      0.94       200\n",
      "weighted avg       0.95      0.95      0.95       200\n"
     ]
    }
   ],
   "source": [
    "## Logistic Regression with Scaled data\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LogReg_scl = LogisticRegression(random_state = 2)\n",
    "\n",
    "LogReg_scl.fit(Xtrain_scaled,Ytrain)\n",
    "\n",
    "predicted_values = LogReg_scl.predict(Xtest_scaled)\n",
    "\n",
    "x = metrics.accuracy_score(Ytest, predicted_values)\n",
    "acc.append(x*100)\n",
    "model.append('Logistic Regression on Scaled data')\n",
    "print(\"Logistic Regression on Scaled data Accuracy is: \",x*100)\n",
    "\n",
    "print(classification_report(Ytest,predicted_values))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T06:25:26.795193Z",
     "start_time": "2024-03-20T06:25:26.772318400Z"
    }
   },
   "id": "db46b1c1da0d714a",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest's Accuracy is:  98.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        21\n",
      "           1       0.95      0.86      0.90        21\n",
      "           2       1.00      1.00      1.00        17\n",
      "           3       1.00      1.00      1.00        17\n",
      "           4       1.00      1.00      1.00        24\n",
      "           5       1.00      1.00      1.00        21\n",
      "           6       1.00      1.00      1.00        15\n",
      "           7       1.00      1.00      1.00        28\n",
      "           8       0.83      1.00      0.91        15\n",
      "           9       1.00      1.00      1.00        21\n",
      "\n",
      "    accuracy                           0.98       200\n",
      "   macro avg       0.98      0.98      0.98       200\n",
      "weighted avg       0.98      0.98      0.98       200\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RF = RandomForestClassifier(n_estimators=20, random_state=0)\n",
    "RF.fit(Xtrain,Ytrain)\n",
    "\n",
    "predicted_values = RF.predict(Xtest)\n",
    "\n",
    "x = metrics.accuracy_score(Ytest, predicted_values)\n",
    "acc.append(x*100)\n",
    "model.append('Random Forest')\n",
    "print(\"Random forest's Accuracy is: \",x*100)\n",
    "\n",
    "print(classification_report(Ytest,predicted_values))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T06:25:34.571981600Z",
     "start_time": "2024-03-20T06:25:34.361063100Z"
    }
   },
   "id": "f4a1f14872c033c8",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[95.5, 98.0, 22.5, 96.0, 95.0, 98.0]"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T06:25:41.360215100Z",
     "start_time": "2024-03-20T06:25:41.327690800Z"
    }
   },
   "id": "77c56a43dbad1c47",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['Decision Tree',\n 'Naive Bayes',\n 'SVM',\n 'Logistic Regression',\n 'Logistic Regression on Scaled data',\n 'Random Forest']"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T06:26:05.721566100Z",
     "start_time": "2024-03-20T06:26:05.713714100Z"
    }
   },
   "id": "d82469693e6b8454",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                            Algorithm  Accuracy of Model\n0                       Decision Tree               95.5\n1                         Naive Bayes               98.0\n2                                 SVM               22.5\n3                 Logistic Regression               96.0\n4  Logistic Regression on Scaled data               95.0\n5                       Random Forest               98.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Algorithm</th>\n      <th>Accuracy of Model</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Decision Tree</td>\n      <td>95.5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Naive Bayes</td>\n      <td>98.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>SVM</td>\n      <td>22.5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Logistic Regression</td>\n      <td>96.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Logistic Regression on Scaled data</td>\n      <td>95.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Random Forest</td>\n      <td>98.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl_df = pd.DataFrame()\n",
    "\n",
    "mdl_df['Algorithm'] = model\n",
    "mdl_df['Accuracy of Model'] = acc\n",
    "\n",
    "mdl_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T06:26:08.057791700Z",
     "start_time": "2024-03-20T06:26:08.025072400Z"
    }
   },
   "id": "efc2ea3a2fe1ddd6",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mitbo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "C:\\Users\\mitbo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "C:\\Users\\mitbo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\seaborn\\_oldcore.py:1765: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  order = pd.unique(vector)\n",
      "C:\\Users\\mitbo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Axes: title={'center': 'Accuracy Comparison'}, xlabel='Accuracy', ylabel='Algorithm'>"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 1000x500 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=[10,5],dpi = 100)\n",
    "plt.title('Accuracy Comparison')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Algorithm')\n",
    "sns.barplot(x = acc,y = model,palette='dark')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T06:26:16.825145Z",
     "start_time": "2024-03-20T06:26:16.614656900Z"
    }
   },
   "id": "ff19c445e9d37789",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data = np.array([[25,7, 35, 28.38, 99.18, 5.55, 189.67]])\n",
    "\n",
    "prediction = RF.predict(data)\n",
    "print(prediction)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T06:26:21.158656700Z",
     "start_time": "2024-03-20T06:26:21.138982800Z"
    }
   },
   "id": "9d0342d5f103d129",
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9]\n"
     ]
    }
   ],
   "source": [
    "data = np.array([[83, 45, 60, 28, 70.3, 7.0, 150.9]])\n",
    "prediction = RF.predict(data)\n",
    "print(prediction)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T06:26:22.383956300Z",
     "start_time": "2024-03-20T06:26:22.364628700Z"
    }
   },
   "id": "b01779d625ac67a7",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "%load_ext sql"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T10:11:01.889929200Z",
     "start_time": "2024-03-21T10:11:00.824206800Z"
    }
   },
   "id": "fe3bdf2f81a86925",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2 in c:\\users\\mitbo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.9.9)\n",
      "Requirement already satisfied: ipython-sql in c:\\users\\mitbo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.5.0)\n",
      "Requirement already satisfied: prettytable in c:\\users\\mitbo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython-sql) (3.10.0)\n",
      "Requirement already satisfied: ipython in c:\\users\\mitbo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython-sql) (8.20.0)\n",
      "Requirement already satisfied: sqlalchemy>=2.0 in c:\\users\\mitbo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython-sql) (2.0.28)\n",
      "Requirement already satisfied: sqlparse in c:\\users\\mitbo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython-sql) (0.4.4)\n",
      "Requirement already satisfied: six in c:\\users\\mitbo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython-sql) (1.16.0)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\mitbo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython-sql) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\mitbo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sqlalchemy>=2.0->ipython-sql) (4.9.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\mitbo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sqlalchemy>=2.0->ipython-sql) (3.0.3)\n",
      "Requirement already satisfied: decorator in c:\\users\\mitbo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython->ipython-sql) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\mitbo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython->ipython-sql) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\mitbo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython->ipython-sql) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\mitbo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython->ipython-sql) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\mitbo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython->ipython-sql) (2.17.2)\n",
      "Requirement already satisfied: stack-data in c:\\users\\mitbo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython->ipython-sql) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5 in c:\\users\\mitbo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython->ipython-sql) (5.14.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\mitbo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython->ipython-sql) (0.4.6)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\mitbo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from prettytable->ipython-sql) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\mitbo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jedi>=0.16->ipython->ipython-sql) (0.8.3)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\mitbo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from stack-data->ipython->ipython-sql) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\mitbo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from stack-data->ipython->ipython-sql) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\mitbo\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from stack-data->ipython->ipython-sql) (0.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install psycopg2 ipython-sql"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-20T12:44:34.630837400Z",
     "start_time": "2024-03-20T12:44:32.351135Z"
    }
   },
   "id": "cb159e8c5e8cbf7a",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\n",
    "    dbname=\"pgml_9mrdvtwlup0tw77\",\n",
    "    user=\"u_r4i5xrjkii5eqag\",\n",
    "    password=\"rinkeoaj2qaptx5\",\n",
    "    host=\"02f7e6f1-1adb-4347-835a-02c74fcccb0e.db.cloud.postgresml.org\",\n",
    "    port=\"6432\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T10:11:07.675319200Z",
     "start_time": "2024-03-21T10:11:05.485262600Z"
    }
   },
   "id": "978d5e39eb43d76f",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%sql postgresql://u_r4i5xrjkii5eqag:rinkeoaj2qaptx5@02f7e6f1-1adb-4347-835a-02c74fcccb0e.db.cloud.postgresml.org:6432/pgml_9mrdvtwlup0tw77"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T10:11:15.868915300Z",
     "start_time": "2024-03-21T10:11:11.079203700Z"
    }
   },
   "id": "ddc9670488e8a2ff",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://u_r4i5xrjkii5eqag:***@02f7e6f1-1adb-4347-835a-02c74fcccb0e.db.cloud.postgresml.org:6432/pgml_9mrdvtwlup0tw77\n",
      "5 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": "[(0.016666667, 0.135714286, 0.165, 0.451362984, 0.848253275, 0.404011461, 0.401312049, 0),\n (0.05, 0.092857143, 0.16, 0.310760402, 0.817321689, 0.40974212, 0.384167942, 0),\n (0.066666667, 0.15, 0.155, 0.285509326, 0.771106259, 0.656160458, 0.359982506, 0),\n (0.308333333, 0.092857143, 0.17, 0.439598278, 0.900473071, 0.547277937, 0.393702165, 0),\n (0.0, 0.157142857, 0.165, 0.390817791, 0.816593886, 0.638968481, 0.390028428, 0)]",
      "text/html": "<table>\n    <thead>\n        <tr>\n            <th>n</th>\n            <th>p</th>\n            <th>k</th>\n            <th>temperature</th>\n            <th>humidity</th>\n            <th>ph</th>\n            <th>rainfall</th>\n            <th>label</th>\n        </tr>\n    </thead>\n    <tbody>\n        <tr>\n            <td>0.016666667</td>\n            <td>0.135714286</td>\n            <td>0.165</td>\n            <td>0.451362984</td>\n            <td>0.848253275</td>\n            <td>0.404011461</td>\n            <td>0.401312049</td>\n            <td>0</td>\n        </tr>\n        <tr>\n            <td>0.05</td>\n            <td>0.092857143</td>\n            <td>0.16</td>\n            <td>0.310760402</td>\n            <td>0.817321689</td>\n            <td>0.40974212</td>\n            <td>0.384167942</td>\n            <td>0</td>\n        </tr>\n        <tr>\n            <td>0.066666667</td>\n            <td>0.15</td>\n            <td>0.155</td>\n            <td>0.285509326</td>\n            <td>0.771106259</td>\n            <td>0.656160458</td>\n            <td>0.359982506</td>\n            <td>0</td>\n        </tr>\n        <tr>\n            <td>0.308333333</td>\n            <td>0.092857143</td>\n            <td>0.17</td>\n            <td>0.439598278</td>\n            <td>0.900473071</td>\n            <td>0.547277937</td>\n            <td>0.393702165</td>\n            <td>0</td>\n        </tr>\n        <tr>\n            <td>0.0</td>\n            <td>0.157142857</td>\n            <td>0.165</td>\n            <td>0.390817791</td>\n            <td>0.816593886</td>\n            <td>0.638968481</td>\n            <td>0.390028428</td>\n            <td>0</td>\n        </tr>\n    </tbody>\n</table>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT * FROM crop_r LIMIT 5;"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T10:11:18.119267700Z",
     "start_time": "2024-03-21T10:11:17.232003500Z"
    }
   },
   "id": "a4d406a7b560e00f",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://u_r4i5xrjkii5eqag:***@02f7e6f1-1adb-4347-835a-02c74fcccb0e.db.cloud.postgresml.org:6432/pgml_9mrdvtwlup0tw77\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": "[('Crop Recommendation', 'classification', 'svm', True)]",
      "text/html": "<table>\n    <thead>\n        <tr>\n            <th>project</th>\n            <th>task</th>\n            <th>algorithm</th>\n            <th>deployed</th>\n        </tr>\n    </thead>\n    <tbody>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>classification</td>\n            <td>svm</td>\n            <td>True</td>\n        </tr>\n    </tbody>\n</table>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT * FROM pgml.train(\n",
    "    project_name => 'Crop Recommendation',\n",
    "    task => 'classification',\n",
    "    relation_name => 'crop_r',\n",
    "    y_column_name => 'label',\n",
    "    algorithm => 'svm',\n",
    "    test_size => 0.3\n",
    ");"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T10:12:04.428619200Z",
     "start_time": "2024-03-21T10:12:02.918932400Z"
    }
   },
   "id": "129f366f5886e608",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://u_r4i5xrjkii5eqag:***@02f7e6f1-1adb-4347-835a-02c74fcccb0e.db.cloud.postgresml.org:6432/pgml_9mrdvtwlup0tw77\n",
      "1 rows affected.\n",
      "1 rows affected.\n",
      "1 rows affected.\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": "[('Crop Recommendation', 'classification', 'passive_aggressive', True)]",
      "text/html": "<table>\n    <thead>\n        <tr>\n            <th>project</th>\n            <th>task</th>\n            <th>algorithm</th>\n            <th>deployed</th>\n        </tr>\n    </thead>\n    <tbody>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>classification</td>\n            <td>passive_aggressive</td>\n            <td>True</td>\n        </tr>\n    </tbody>\n</table>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT * FROM pgml.train('Crop Recommendation', algorithm => 'ridge',test_size => 0.3);\n",
    "SELECT * FROM pgml.train('Crop Recommendation', algorithm => 'stochastic_gradient_descent',test_size => 0.3);\n",
    "SELECT * FROM pgml.train('Crop Recommendation', algorithm => 'perceptron',test_size => 0.3);\n",
    "SELECT * FROM pgml.train('Crop Recommendation', algorithm => 'passive_aggressive',test_size => 0.3);"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T10:12:51.565881Z",
     "start_time": "2024-03-21T10:12:47.774346700Z"
    }
   },
   "id": "6a804c60898480e3",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://u_r4i5xrjkii5eqag:***@02f7e6f1-1adb-4347-835a-02c74fcccb0e.db.cloud.postgresml.org:6432/pgml_9mrdvtwlup0tw77\n",
      "69 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": "[('Crop Recommendation', None, None, None),\n ('Crop Recommendation', None, None, None),\n ('Crop Recommendation', None, None, None),\n ('Crop Recommendation', None, None, None),\n ('Crop Recommendation', Decimal('1'), Decimal('1'), Decimal('1')),\n ('Crop Recommendation', None, None, None),\n ('Crop Recommendation', None, None, None),\n ('Crop Recommendation', None, None, None),\n ('Crop Recommendation', Decimal('1'), Decimal('1'), Decimal('1')),\n ('Crop Recommendation', None, None, None),\n ('Crop Recommendation', None, None, None),\n ('Crop Recommendation', Decimal('1'), Decimal('1'), Decimal('1')),\n ('Crop Recommendation', None, None, None),\n ('Crop Recommendation', Decimal('1'), Decimal('1'), Decimal('1')),\n ('Crop Recommendation', None, None, None),\n ('Crop Recommendation', None, None, None),\n ('Crop Recommendation', None, None, None),\n ('Crop Recommendation', None, None, None),\n ('Crop Recommendation', None, None, None),\n ('Crop Recommendation', None, None, None),\n ('Crop Recommendation', None, None, None),\n ('Crop Recommendation', None, None, None),\n ('Crop Recommendation', None, None, None),\n ('Crop Recommendation', None, None, None),\n ('Crop Recommendation', None, None, None),\n ('Crop Recommendation', Decimal('1'), Decimal('1'), Decimal('1')),\n ('Crop Recommendation', None, None, None),\n ('Crop Recommendation', None, None, None),\n ('Crop Recommendation', None, None, None),\n ('Crop Recommendation', None, None, None),\n ('Crop Recommendation', Decimal('1'), Decimal('1'), Decimal('1')),\n ('Crop Recommendation', None, None, None),\n ('Crop Recommendation', Decimal('1'), Decimal('1'), Decimal('1')),\n ('Crop Recommendation', None, None, None),\n ('Crop Recommendation', None, None, None),\n ('Crop Recommendation', Decimal('1'), Decimal('1'), Decimal('1')),\n ('Crop Recommendation', None, Decimal('0'), None),\n ('Crop Recommendation', Decimal('1'), Decimal('0'), Decimal('1')),\n ('Crop Recommendation', Decimal('1'), Decimal('1'), Decimal('1')),\n ('Crop Recommendation', Decimal('1'), Decimal('1'), Decimal('1')),\n ('Crop Recommendation', Decimal('1'), Decimal('1'), Decimal('1')),\n ('Crop Recommendation', Decimal('1'), Decimal('1'), Decimal('1')),\n ('Crop Recommendation', Decimal('1'), Decimal('1'), Decimal('1')),\n ('Crop Recommendation', Decimal('1'), Decimal('1'), Decimal('1')),\n ('Crop Recommendation', Decimal('1'), Decimal('1'), Decimal('1')),\n ('Crop Recommendation', Decimal('1'), Decimal('1'), Decimal('1')),\n ('Crop Recommendation', Decimal('1'), Decimal('1'), Decimal('1')),\n ('Crop Recommendation', Decimal('1'), Decimal('1'), Decimal('1')),\n ('Crop Recommendation', Decimal('1'), Decimal('1'), Decimal('1')),\n ('Crop Recommendation', Decimal('1'), Decimal('1'), Decimal('1')),\n ('Crop Recommendation', Decimal('1'), Decimal('1'), Decimal('1')),\n ('Crop Recommendation', Decimal('1'), Decimal('1'), Decimal('1')),\n ('Crop Recommendation', Decimal('1'), Decimal('1'), Decimal('1')),\n ('Crop Recommendation', Decimal('1'), Decimal('1'), Decimal('1')),\n ('Crop Recommendation', Decimal('1'), Decimal('1'), Decimal('1')),\n ('Crop Recommendation', Decimal('1'), Decimal('1'), Decimal('1')),\n ('Crop Recommendation', Decimal('1'), Decimal('1'), Decimal('1')),\n ('Crop Recommendation', Decimal('1'), Decimal('1'), Decimal('1')),\n ('Crop Recommendation', Decimal('1'), Decimal('1'), Decimal('1')),\n ('Crop Recommendation', Decimal('1'), Decimal('1'), Decimal('1')),\n ('Crop Recommendation', Decimal('1'), Decimal('1'), Decimal('1')),\n ('Crop Recommendation', Decimal('1'), Decimal('1'), Decimal('1')),\n ('Crop Recommendation', Decimal('1'), Decimal('1'), Decimal('1')),\n ('Crop Recommendation', Decimal('1'), Decimal('1'), Decimal('1')),\n ('Crop Recommendation', None, None, None),\n ('Crop Recommendation', None, None, None),\n ('Crop Recommendation', None, None, None),\n ('Crop Recommendation', None, None, None),\n ('Crop Recommendation', None, None, None)]",
      "text/html": "<table>\n    <thead>\n        <tr>\n            <th>?column?</th>\n            <th>f1_score</th>\n            <th>precision</th>\n            <th>recall</th>\n        </tr>\n    </thead>\n    <tbody>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>None</td>\n            <td>None</td>\n            <td>None</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>None</td>\n            <td>None</td>\n            <td>None</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>None</td>\n            <td>None</td>\n            <td>None</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>None</td>\n            <td>None</td>\n            <td>None</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>1</td>\n            <td>1</td>\n            <td>1</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>None</td>\n            <td>None</td>\n            <td>None</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>None</td>\n            <td>None</td>\n            <td>None</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>None</td>\n            <td>None</td>\n            <td>None</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>1</td>\n            <td>1</td>\n            <td>1</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>None</td>\n            <td>None</td>\n            <td>None</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>None</td>\n            <td>None</td>\n            <td>None</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>1</td>\n            <td>1</td>\n            <td>1</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>None</td>\n            <td>None</td>\n            <td>None</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>1</td>\n            <td>1</td>\n            <td>1</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>None</td>\n            <td>None</td>\n            <td>None</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>None</td>\n            <td>None</td>\n            <td>None</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>None</td>\n            <td>None</td>\n            <td>None</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>None</td>\n            <td>None</td>\n            <td>None</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>None</td>\n            <td>None</td>\n            <td>None</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>None</td>\n            <td>None</td>\n            <td>None</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>None</td>\n            <td>None</td>\n            <td>None</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>None</td>\n            <td>None</td>\n            <td>None</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>None</td>\n            <td>None</td>\n            <td>None</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>None</td>\n            <td>None</td>\n            <td>None</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>None</td>\n            <td>None</td>\n            <td>None</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>1</td>\n            <td>1</td>\n            <td>1</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>None</td>\n            <td>None</td>\n            <td>None</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>None</td>\n            <td>None</td>\n            <td>None</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>None</td>\n            <td>None</td>\n            <td>None</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>None</td>\n            <td>None</td>\n            <td>None</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>1</td>\n            <td>1</td>\n            <td>1</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>None</td>\n            <td>None</td>\n            <td>None</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>1</td>\n            <td>1</td>\n            <td>1</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>None</td>\n            <td>None</td>\n            <td>None</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>None</td>\n            <td>None</td>\n            <td>None</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>1</td>\n            <td>1</td>\n            <td>1</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>None</td>\n            <td>0</td>\n            <td>None</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>1</td>\n            <td>0</td>\n            <td>1</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>1</td>\n            <td>1</td>\n            <td>1</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>1</td>\n            <td>1</td>\n            <td>1</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>1</td>\n            <td>1</td>\n            <td>1</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>1</td>\n            <td>1</td>\n            <td>1</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>1</td>\n            <td>1</td>\n            <td>1</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>1</td>\n            <td>1</td>\n            <td>1</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>1</td>\n            <td>1</td>\n            <td>1</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>1</td>\n            <td>1</td>\n            <td>1</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>1</td>\n            <td>1</td>\n            <td>1</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>1</td>\n            <td>1</td>\n            <td>1</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>1</td>\n            <td>1</td>\n            <td>1</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>1</td>\n            <td>1</td>\n            <td>1</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>1</td>\n            <td>1</td>\n            <td>1</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>1</td>\n            <td>1</td>\n            <td>1</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>1</td>\n            <td>1</td>\n            <td>1</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>1</td>\n            <td>1</td>\n            <td>1</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>1</td>\n            <td>1</td>\n            <td>1</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>1</td>\n            <td>1</td>\n            <td>1</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>1</td>\n            <td>1</td>\n            <td>1</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>1</td>\n            <td>1</td>\n            <td>1</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>1</td>\n            <td>1</td>\n            <td>1</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>1</td>\n            <td>1</td>\n            <td>1</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>1</td>\n            <td>1</td>\n            <td>1</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>1</td>\n            <td>1</td>\n            <td>1</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>1</td>\n            <td>1</td>\n            <td>1</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>1</td>\n            <td>1</td>\n            <td>1</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>None</td>\n            <td>None</td>\n            <td>None</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>None</td>\n            <td>None</td>\n            <td>None</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>None</td>\n            <td>None</td>\n            <td>None</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>None</td>\n            <td>None</td>\n            <td>None</td>\n        </tr>\n        <tr>\n            <td>Crop Recommendation</td>\n            <td>None</td>\n            <td>None</td>\n            <td>None</td>\n        </tr>\n    </tbody>\n</table>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT \n",
    "  'Crop Recommendation',\n",
    "  round((metrics->>'f1')::numeric) AS f1_score,\n",
    "  round((metrics->>'precision')::numeric) AS precision,\n",
    "  round((metrics->>'recall')::numeric) AS recall\n",
    "FROM pgml.models;"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T10:14:11.573655300Z",
     "start_time": "2024-03-21T10:14:10.614390400Z"
    }
   },
   "id": "e1fb32c68cd0c23c",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6025c5bd849f3e0d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://u_r4i5xrjkii5eqag:***@02f7e6f1-1adb-4347-835a-02c74fcccb0e.db.cloud.postgresml.org:6432/pgml_9mrdvtwlup0tw77\n",
      "1 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/plain": "[(3.0,)]",
      "text/html": "<table>\n    <thead>\n        <tr>\n            <th>predict</th>\n        </tr>\n    </thead>\n    <tbody>\n        <tr>\n            <td>3.0</td>\n        </tr>\n    </tbody>\n</table>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT pgml.predict(\n",
    "    'Crop Recommendation'::text, \n",
    "    ARRAY[0.275,0.957142857,0.99,0.703299857,0.68213246,0.338108883,0.220730374\n",
    "]::FLOAT[]\n",
    ");"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-21T10:19:13.177834800Z",
     "start_time": "2024-03-21T10:19:12.188547200Z"
    }
   },
   "id": "aa7f55a7e6cdfe19",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "811475f72e46698f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
